{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key papers\n",
    "\n",
    "This Jupyter Notebook can be used to perform basic publication analysis for a science branch. \n",
    "\n",
    "**Features:**\n",
    "\n",
    "1. Subtopic analysis based on co-citation, bibliographic coupling graph clustering:\n",
    "    * Chord diagram for co-citation graph\n",
    "    * Comparison of subtopics by size\n",
    "    * Timeline of each subtopic\n",
    "    * TF-IDF based description for each topic\n",
    "2. Detection of highlight papers:\n",
    "    * Top cited papers overall\n",
    "    * Detection of most cited papers for each year\n",
    "    * Detection of papers with max relative citation gain for each year\n",
    "3. Citation dynamics visualization for highlight papers\n",
    "4. Subtopic evolution tracking based on co-citation graph clustering for different time periods\n",
    "\n",
    "**IMPORTANT** \n",
    "Turn on experimental features in config file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "1. Define the `SEARCH_QUERY` variable in the cell below with a list of keywords that describe the science branch of your interest.\n",
    "2. Run all cells & see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T11:13:20.757962Z",
     "start_time": "2019-05-20T11:13:19.650470Z"
    }
   },
   "outputs": [],
   "source": [
    "SEARCH_QUERY = 'human aging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T11:13:45.558630Z",
     "start_time": "2019-05-20T11:13:20.941831Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from bokeh.plotting import show, output_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keypaper.config import PubtrendsConfig\n",
    "from keypaper.pm_loader import PubmedLoader\n",
    "from keypaper.ss_loader import SemanticScholarLoader\n",
    "from keypaper.analysis import KeyPaperAnalyzer\n",
    "from keypaper.visualization import Plotter\n",
    "from models.keypaper.utils import SORT_MOST_CITED, SORT_MOST_RELEVANT, SORT_MOST_RECENT, cut_authors_list\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "output_notebook()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_SORT = SORT_MOST_CITED\n",
    "SEARCH_PAPERS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:00:33.794284Z",
     "start_time": "2019-05-20T11:13:45.591588Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = PubtrendsConfig(test=False)\n",
    "loader = SemanticScholarLoader(config)\n",
    "analyzer = KeyPaperAnalyzer(loader, config)\n",
    "try:\n",
    "    ids = analyzer.search_terms(SEARCH_QUERY, limit=SEARCH_PAPERS, sort=SEARCH_SORT)\n",
    "    analyzer.analyze_papers(ids, SEARCH_QUERY)\n",
    "finally:\n",
    "    loader.close_connection()\n",
    "    analyzer.teardown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph visualization\n",
    "\n",
    "In cytoscape format for visual analysis. Use `vis/index.html` for visualization in a web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keypaper.visualization import PlotPreprocessor\n",
    "\n",
    "cg_cytoscape = PlotPreprocessor.dump_citations_graph_cytoscape(analyzer.df, analyzer.citations_graph)\n",
    "print(cg_cytoscape)\n",
    "search_str = SEARCH_QUERY.lower().replace(' ', '_')\n",
    "sort_str = SEARCH_SORT.lower().replace(' ', '_')\n",
    "\n",
    "\n",
    "with open(f'vis/citations_graph_{search_str}_{sort_str}_{SEARCH_PAPERS}.json', 'w') as f:\n",
    "    json.dump(cg_cytoscape, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Paper relations graph edge weights')\n",
    "weights = [w for (_, _, w) in analyzer.paper_relations_graph.edges.data('weight')]\n",
    "plt.hist(weights, bins=[1, 2, 5, 10, 20, 50, 100])\n",
    "plt.show()\n",
    "\n",
    "# We want to show 1000 edges or 10%, what is bigger\n",
    "weight_cutoff = np.percentile(weights, min(100 - (100 * 1000 / len(weights)), 90))\n",
    "print('Cutoff', weight_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from bokeh.palettes import Category20\n",
    "\n",
    "comp_colors = dict(enumerate(Category20[20]))\n",
    "prgc = analyzer.paper_relations_graph.copy()\n",
    "\n",
    "print(\"Prune papers relationships edges with small weight for visualization\")\n",
    "for u, v in [(u, v) for (u, v, w) in analyzer.paper_relations_graph.edges.data('weight') if w < weight_cutoff]:\n",
    "    prgc.remove_edge(u, v)\n",
    "\n",
    "# Collect attributes for nodes\n",
    "attrs = {}\n",
    "for node in analyzer.ids:\n",
    "    if not prgc.has_node(node):\n",
    "        prgc.add_node(node)\n",
    "    \n",
    "    sel = analyzer.df[analyzer.df['id'] == node]\n",
    "    attrs[node] = {'title': sel['title'].values[0],\n",
    "                   'authors': cut_authors_list(sel['authors'].values[0]),\n",
    "                   'year': int(sel['year'].values[0]), \n",
    "                   'cited': int(sel['total'].values[0]),\n",
    "                   'pagerank': 'N/A',\n",
    "                   'size': 10 * np.log1p(int(sel['total'].values[0])) + 5,\n",
    "                   'color': comp_colors[int(sel['comp'].values[0])]}\n",
    "nx.set_node_attributes(prgc, attrs)\n",
    "with open(f'vis/paper_relations_graph_{search_str}_{sort_str}_{SEARCH_PAPERS}.json', 'w') as f:\n",
    "    json.dump(nx.cytoscape_data(prgc), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:00:35.056256Z",
     "start_time": "2019-05-20T12:00:34.356360Z"
    }
   },
   "outputs": [],
   "source": [
    "plotter = Plotter(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top cited papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.top_cited_papers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.max_gain_papers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.max_relative_gain_papers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single paper citations dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show(plotter.article_citation_dynamics(analyzer.df, str(24138928)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtopics a.k.a. Clusters in the Co-citation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, wc, _ = plotter.papers_statistics_and_word_cloud_and_callback()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wc.layout_)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.component_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.chord_diagram_components())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:00:45.632292Z",
     "start_time": "2019-05-20T12:00:35.064248Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(plotter.cocitations_clustering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:00:48.074797Z",
     "start_time": "2019-05-20T12:00:45.760212Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(plotter.component_size_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.component_years_summary_boxplots())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:01:26.334327Z",
     "start_time": "2019-05-20T12:00:48.085780Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for p, _, _ in plotter.subtopics_info_and_word_cloud_and_callback():\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:02:52.682050Z",
     "start_time": "2019-05-20T12:02:49.182634Z"
    }
   },
   "outputs": [],
   "source": [
    "p = plotter.subtopic_evolution()\n",
    "if p is None:\n",
    "    logging.info('Step is too large to analyze subtopic evolution')\n",
    "else:\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank for Citation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:20:18.552985Z",
     "start_time": "2019-05-20T12:15:08.834Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Apply PageRank algorithm with damping factor of 0.5\n",
    "pr_nx = nx.pagerank(analyzer.G, alpha=0.5, tol=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:20:18.078073Z",
     "start_time": "2019-05-20T11:13:20.732Z"
    }
   },
   "outputs": [],
   "source": [
    "ancestor = dict.fromkeys(analyzer.G, (0, 0))\n",
    "\n",
    "# Select ancestor with highest PR for each node\n",
    "for v in analyzer.G:\n",
    "    for u in analyzer.G[v]:\n",
    "        anc, pr = ancestor[u]\n",
    "        if pr_nx[v] > pr:\n",
    "            ancestor[u] = (v, pr_nx[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:20:18.118051Z",
     "start_time": "2019-05-20T11:13:20.740Z"
    }
   },
   "outputs": [],
   "source": [
    "PRG = nx.DiGraph()\n",
    "for v, anc in ancestor.items():\n",
    "    u, pr = anc\n",
    "    if pr > 0:\n",
    "        PRG.add_edge(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:20:18.145031Z",
     "start_time": "2019-05-20T11:13:20.832Z"
    }
   },
   "outputs": [],
   "source": [
    "start, end = zip(*list(PRG.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:20:18.179011Z",
     "start_time": "2019-05-20T11:13:25.347Z"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GraphRenderer, StaticLayoutProvider, Circle, HoverTool, MultiLine\n",
    "from bokeh.models.graphs import NodesAndLinkedEdges\n",
    "\n",
    "node_indices = list(filter(lambda node: len(analyzer.df[analyzer.df['id'] == node]) > 0, list(PRG.nodes())))\n",
    "\n",
    "years = []\n",
    "year_counts = {}\n",
    "titles = []\n",
    "pageranks = []\n",
    "size = []\n",
    "for node in node_indices:\n",
    "    sel = analyzer.df[analyzer.df['id'] == node]\n",
    "    year = sel['year'].values[0]\n",
    "    \n",
    "    if not year in year_counts:\n",
    "        year_counts[year] = 1\n",
    "    else:\n",
    "        year_counts[year] += 1\n",
    "    years.append(year)\n",
    "    \n",
    "    titles.append(sel['title'].values[0])\n",
    "    pageranks.append(pr_nx[node] * 100)\n",
    "    size.append(pr_nx[node] * 1000)\n",
    "max_year_count = max(list(year_counts.values()))\n",
    "min_year, max_year = min(years), max(years)\n",
    "\n",
    "plot = figure(title=\"PageRank applied to citation filtering\", \n",
    "              x_range=(min_year - 1, max_year+1), y_range=(0, max_year_count + 1),\n",
    "              tools=\"\", toolbar_location=None)\n",
    "\n",
    "TOOLTIPS = \"\"\"\n",
    "    <div style=\"max-width: 320px\">\n",
    "        <div>\n",
    "            <span style=\"font-size: 12px; font-weight: bold;\">@title</span>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style=\"font-size: 11px;\">Year</span>\n",
    "            <span style=\"font-size: 10px;\">@year</span>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style=\"font-size: 11px;\">PMID</span>\n",
    "            <span style=\"font-size: 10px;\">@id</span>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style=\"font-size: 11px;\">PageRank</span>\n",
    "            <span style=\"font-size: 10px;\">@pagerank</span>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=TOOLTIPS))\n",
    "\n",
    "graph = GraphRenderer()\n",
    "\n",
    "graph.node_renderer.data_source.add(node_indices, 'index')\n",
    "graph.node_renderer.data_source.data['id'] = node_indices\n",
    "graph.node_renderer.data_source.data['year'] = years\n",
    "graph.node_renderer.data_source.data['title'] = titles\n",
    "graph.node_renderer.data_source.data['pagerank'] = pageranks\n",
    "graph.node_renderer.data_source.data['size'] = size\n",
    "# graph.edge_renderer.data_source.data = dict(start=start, end=end)\n",
    "\n",
    "### start of layout code   \n",
    "x = [analyzer.df[analyzer.df['id'] == pmid]['year'].values[0] for pmid in node_indices]\n",
    "y = []\n",
    "tmp_year_counts = {}\n",
    "for node in node_indices:\n",
    "    year = analyzer.df[analyzer.df['id'] == node]['year'].values[0]\n",
    "    if not year in tmp_year_counts:\n",
    "        tmp_year_counts[year] = 1\n",
    "    else:\n",
    "        tmp_year_counts[year] += 1\n",
    "    y.append(tmp_year_counts[year])\n",
    "\n",
    "graph_layout = dict(zip(node_indices, zip(x, y)))\n",
    "graph.layout_provider = StaticLayoutProvider(graph_layout=graph_layout)\n",
    "\n",
    "graph.node_renderer.glyph = Circle(size='size', fill_color='blue')\n",
    "graph.node_renderer.hover_glyph = Circle(size='size', fill_color='green')\n",
    "\n",
    "# graph.edge_renderer.glyph = MultiLine(line_color='black', line_alpha=1, line_width=1)\n",
    "# graph.edge_renderer.hover_glyph = MultiLine(line_color='green', line_width=2)\n",
    "\n",
    "graph.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "plot.min_border_left = 75\n",
    "plot.renderers.append(graph)\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Papers by PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pmid, pagerank in sorted(pr_nx.items(), key=lambda el: el[1], reverse=True)[:10]:\n",
    "    print(f\"{(100*pagerank):.2f} {analyzer.df[analyzer.df['id'] == pmid]['title'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank and citation ranking correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "analyzer.df['citation_rank'] = analyzer.df['total'].rank(method='first', ascending=False)\n",
    "pagerank_rank = sorted(pr_nx.items(), key=lambda el: el[1], reverse=True)\n",
    "\n",
    "r = np.zeros((len(pagerank_rank), 2))\n",
    "for i, (pmid, pr) in enumerate(pagerank_rank):\n",
    "    sel = analyzer.df[analyzer.df['id'] == pmid]\n",
    "    if len(sel) > 0:\n",
    "        r[i, 0] = i\n",
    "        r[i, 1] = int(sel['citation_rank'].values[0])\n",
    "        \n",
    "TOP_X = [5, 10, 30, 50, 100]\n",
    "for x in TOP_X:\n",
    "    rho, _ = spearmanr(r[:x, 0], r[:x, 1])\n",
    "    print(f'Spearman correlation coefficient for top {x}: {rho}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very slow!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "adj = np.zeros((analyzer.CG.number_of_nodes(), analyzer.df['comp'].nunique()))\n",
    "w = np.zeros(adj.shape)\n",
    "\n",
    "for i, v in enumerate(analyzer.CG.nodes()):\n",
    "    for u in analyzer.CG[v]:\n",
    "        c = analyzer.df[analyzer.df['id'] == u]['comp'].values[0]\n",
    "        adj[i][c] += 1\n",
    "        w[i][c] += analyzer.CG[v][u]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "size = 10\n",
    "\n",
    "hub_indices = np.argsort(np.sum(adj > 0, axis=1))[-size:]\n",
    "\n",
    "nodes_list = list(analyzer.CG.nodes)\n",
    "hub_pmids = [nodes_list[idx] for idx in hub_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hub nodes')\n",
    "print(analyzer.df[analyzer.df['id'].isin(hub_pmids)][['id', 'title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:20:18.370150Z",
     "start_time": "2019-05-20T11:13:25.415Z"
    }
   },
   "outputs": [],
   "source": [
    "pr = nx.pagerank(analyzer.G, alpha=0.5, tol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
