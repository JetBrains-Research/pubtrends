{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key papers\n",
    "\n",
    "**TOPICS OF INTEREST** - from the meeting in January\n",
    "\n",
    "* inflammation aging chronic (2004) - 13k papers\n",
    "* genome editing / manipulation, CRISPR - 13k papers\n",
    "* induced stem cells - 73k papers - 3h for calculating co-citations\n",
    "* single-cell sequencing (2012) - 3k papers\n",
    "* ATAC-seq (2015) - 276 papers\n",
    "* immunomodulation cancer - 71k papers\n",
    "* Telomere Theories of Aging - ??\n",
    "* mTOR pathway - 14255\n",
    "* autophagy - ??\n",
    "* Calorie restriction - 3933\n",
    "\n",
    "Complement Factor H + Age-Related Mascular Degeneration - investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issues**:\n",
    "\n",
    "1. Some information in tooltips with long titles may occur out of plot bounds.\n",
    "2. How should I place articles with the same year? (currently y-axis position is random in [0,1]...)\n",
    "3. Some research on clustering algorithms is needed! (also `networkx.algorithms.community`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**:\n",
    "\n",
    "1. Subtopic Analysis based on co-citation graph clustering\n",
    "2. Top Cited Papers detection (overall and for certain year)\n",
    "3. Citation Dynamics for a certain article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:30:20.696782Z",
     "start_time": "2019-05-07T09:30:20.672795Z"
    }
   },
   "outputs": [],
   "source": [
    "SEARCH_TERMS = ['single', 'cell', 'rna', 'seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:30:24.117841Z",
     "start_time": "2019-05-07T09:30:20.701784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"2728\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"2728\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"2728\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '2728' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.1.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.1.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.1.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.1.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.1.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.1.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.1.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"2728\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"2728\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"2728\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '2728' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.1.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.1.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.1.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.1.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.1.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.1.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.1.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"2728\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from importlib import reload\n",
    "import logging\n",
    "# reload(logging)\n",
    "\n",
    "import re\n",
    "import gc\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg_driver\n",
    "\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.models import ColumnDataSource, LabelSet, OpenURL, CustomJS\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.colors import Color, RGB\n",
    "from bokeh.io import show\n",
    "from bokeh.models import Plot, Range1d, MultiLine, Circle\n",
    "# Tools used: hover,pan,tap,wheel_zoom,box_zoom,reset,save\n",
    "from bokeh.models import HoverTool, PanTool, TapTool, WheelZoomTool, BoxZoomTool, ResetTool, SaveTool\n",
    "from bokeh.models.graphs import from_networkx\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import community\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = 'nikolay.kapralov@gmail.com'\n",
    "PUBMED_ARTICLE_BASE_URL = 'https://www.ncbi.nlm.nih.gov/pubmed/?term='\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', level=logging.DEBUG)\n",
    "output_notebook()\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:30:25.117220Z",
     "start_time": "2019-05-07T09:30:24.123836Z"
    }
   },
   "outputs": [],
   "source": [
    "class KeyPaperAnalyzer:       \n",
    "    def __init__(self):\n",
    "        self.conn = pg_driver.connect(dbname='pubmed', user='biolabs', password='pubtrends', host='localhost')\n",
    "        self.cursor = self.conn.cursor()\n",
    "        \n",
    "    def load_publications(self):\n",
    "        logging.info('Loading publication data')\n",
    "        \n",
    "        values = ', '.join(['({})'.format(i) for i in sorted(self.pmids)])\n",
    "        query = re.sub('\\$VALUES\\$', values, '''\n",
    "        DROP TABLE IF EXISTS TEMP_PMIDS;\n",
    "        WITH  vals(pmid) AS (VALUES $VALUES$)\n",
    "        SELECT pmid INTO temporary table TEMP_PMIDS FROM vals;\n",
    "        \n",
    "        DROP INDEX IF EXISTS temp_pmids_unique_index;\n",
    "        CREATE UNIQUE INDEX temp_pmids_unique_index ON TEMP_PMIDS USING btree (pmid);\n",
    "\n",
    "        SELECT P.pmid, P.title, P.year\n",
    "        FROM Publications P\n",
    "        JOIN TEMP_PMIDS AS T ON (P.pmid = T.pmid);\n",
    "        ''')\n",
    "        logging.info('Creating pmids table for request with index.')\n",
    "        with self.conn:\n",
    "            self.cursor.execute(query)\n",
    "            \n",
    "        pub_data = []\n",
    "        for row in self.cursor:\n",
    "            pub_data.append(list(row))\n",
    "        self.pub_df = pd.DataFrame(pub_data, columns=['pmid', 'title', 'year'])\n",
    "        logging.info(f'Found {len(self.pub_df)} publications in the local database')\n",
    "            \n",
    "    def load_cocitations(self):\n",
    "        logging.info('Calculating co-citations for selected articles')\n",
    "\n",
    "        # Optimize WHERE with JOIN (VALUES ... ) AS\n",
    "        # instead of WHERE C1.pmid_cited = ANY(%s) AND C2.pmid_cited = ANY(%s)\n",
    "        # See https://pgday.ru/files/pgmaster14/max.boguk.query.optimization.pdf\n",
    "        query = '''\n",
    "        SELECT C1.pmid_citing, C1.pmid_cited, C2.pmid_cited, P.year\n",
    "        FROM Citations C1\n",
    "        JOIN TEMP_PMIDS AS T1 ON (C1.pmid_cited = T1.pmid)\n",
    "        JOIN Citations C2\n",
    "        JOIN TEMP_PMIDS AS T2 ON (C2.pmid_cited = T2.pmid)\n",
    "        ON C1.pmid_citing = C2.pmid_citing AND C1.pmid_cited < C2.pmid_cited\n",
    "        JOIN Publications P\n",
    "        ON C1.pmid_citing = P.pmid;\n",
    "        '''\n",
    "\n",
    "        with self.conn:\n",
    "            self.cursor.execute(query)\n",
    "            \n",
    "        cocit_data = []\n",
    "        for row in self.cursor:\n",
    "            cocit_data.append(list(row))\n",
    "        self.cocit_df = pd.DataFrame(cocit_data, columns=['citing', 'cited_1', 'cited_2', 'year'])\n",
    "        logging.info(f'Found {len(self.cocit_df)} co-cited pairs of articles')\n",
    "        \n",
    "\n",
    "        logging.info(f'Building co-citations graph')\n",
    "        self.cocit_grouped_df = self.cocit_df.groupby(['cited_1', 'cited_2', 'year']).count().reset_index()\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.pivot_table(index=['cited_1', 'cited_2'], \n",
    "                                                          columns=['year'], values=['citing']).reset_index()\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.replace(np.nan, 0)\n",
    "        self.cocit_grouped_df['total'] = self.cocit_grouped_df.iloc[:, 2:].sum(axis=1)\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.sort_values(by='total', ascending=False)\n",
    "        logging.info('Filtering top 10000 or 80% of all the co-citations')\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.iloc[:min(10000, round(0.8 * len(self.cocit_grouped_df))), :]\n",
    "        self.CG = nx.Graph()\n",
    "        # NOTE: we use nodes id as String to avoid problems str keys in jsonify during graph visualization\n",
    "        for el in analyzer.cocit_grouped_df[['cited_1', 'cited_2', 'total']].values.astype(int):\n",
    "            self.CG.add_edge(str(el[0]), str(el[1]), weight=el[2])\n",
    "        logging.info(f'Co-citations graph nodes {len(self.CG.nodes())} edges {len(self.CG.edges())}')\n",
    "            \n",
    "    def load_citation_stats(self):\n",
    "        logging.info('Started loading citation stats')\n",
    "\n",
    "        query = '''\n",
    "        SELECT C.pmid_cited AS pmid, P.year, COUNT(1) AS count\n",
    "        FROM Citations C\n",
    "        JOIN TEMP_PMIDS AS T ON (C.pmid_cited = T.pmid)\n",
    "        JOIN Publications P\n",
    "        ON C.pmid_citing = P.pmid\n",
    "        WHERE P.year > 0\n",
    "        GROUP BY C.pmid_cited, P.year;\n",
    "        '''\n",
    "\n",
    "        with self.conn:\n",
    "            self.cursor.execute(query)\n",
    "        logging.info('Done loading citation stats')\n",
    "\n",
    "        pub_data = []\n",
    "        for row in analyzer.cursor:\n",
    "            pub_data.append(list(row))\n",
    "        self.cit_df = pd.DataFrame(pub_data, columns=['pmid', 'year', 'count'])\n",
    "        \n",
    "        self.cit_df = self.cit_df.pivot(index='pmid', columns='year', values='count').reset_index().replace(np.nan, 0)\n",
    "        self.cit_df['total'] = self.cit_df.iloc[:, 1:].sum(axis = 1)\n",
    "        self.cit_df = self.cit_df.sort_values(by='total', ascending=False)\n",
    "        \n",
    "        logging.info('Filtering top 10000 or 80% of all the papers')\n",
    "        self.cit_df = self.cit_df.iloc[:min(10000, round(0.8 * len(self.cit_df))), :]\n",
    "        logging.info('Done aggregation')\n",
    "        \n",
    "        logging.info(f\"Loaded citation stats for {len(self.cit_df)} of {len(self.pmids)} articles. \" +\n",
    "                    \"Others may either have zero citations or be absent in the local database.\")        \n",
    "            \n",
    "    def plot_total_citations(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        ax = self.cit_df['total'].plot.bar()\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xlabel('Articles')\n",
    "        ax.set_ylabel('Number of citations')\n",
    "    \n",
    "    def search(self, *terms):\n",
    "        print('TODO: handle queries which return more than 1000000 items')\n",
    "        print('TODO: use local database instead of PubMed API')\n",
    "        self.terms = [t.lower() for t in terms]\n",
    "        query=' '.join(terms)\n",
    "        handle = Entrez.esearch(db='pubmed', retmax='1000000', retmode='xml', term=query)\n",
    "        self.pmids = [int(pmid) for pmid in Entrez.read(handle)['IdList']]\n",
    "        logging.info(f'Found {len(self.pmids)} articles about {terms}')       \n",
    "        \n",
    "    def top_cited_papers(self, threshold=0.05):\n",
    "        ids = self.cit_df.iloc[:round(len(self.cit_df) * threshold), 0].values\n",
    "        counts = self.cit_df.iloc[:round(len(self.cit_df) * threshold), -1].values\n",
    "        urls = [PUBMED_ARTICLE_BASE_URL + str(i) for i in ids]\n",
    "        return zip(ids, urls, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:30:25.285118Z",
     "start_time": "2019-05-07T09:30:25.123218Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_data_source(df):\n",
    "    # TODO: use d = ColumnDataSource(df)\n",
    "    d = ColumnDataSource(data=dict(pmid=df['pmid'], title=df['title'], year=df['year'], total=df['total'],\n",
    "                                   size=np.log(df['total']) / 10, pos=np.random.random(size=len(df))))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:30:25.619912Z",
     "start_time": "2019-05-07T09:30:25.292114Z"
    }
   },
   "outputs": [],
   "source": [
    "TOOLS = \"hover,pan,tap,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "def serve_scatter_article_layout(source, title, year_range=None, color='blue'):\n",
    "    callback = CustomJS(args=dict(source=source, base=PUBMED_ARTICLE_BASE_URL), code=\"\"\"\n",
    "        var data = source.data, selected = source.selected.indices;\n",
    "        if (selected.length == 1) {\n",
    "            // only consider case where one glyph is selected by user\n",
    "            selected_id = data['pmid'][selected[0]]\n",
    "            for (var i = 0; i < data['pmid'].length; ++i){\n",
    "                if(data['pmid'][i] == selected_id){\n",
    "                    window.open(base + data['pmid'][i], '_blank');\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\")\n",
    "\n",
    "    p = figure(tools=TOOLS, toolbar_location=\"above\", plot_width=960, plot_height=400, x_range=year_range, title=title)\n",
    "    p.xaxis.axis_label = 'Year'\n",
    "    p.hover.tooltips = [\n",
    "        (\"PMID\", '@pmid'),\n",
    "        (\"Title\", '@title'),\n",
    "        (\"Year\", '@year'),\n",
    "        (\"Cited by\", '@total paper(s) total')\n",
    "    ]\n",
    "    p.js_on_event('tap', callback)\n",
    "\n",
    "    p.circle(x='year', y='pos', fill_alpha=0.5, source=source, radius='size', line_color=color, fill_color=color)\n",
    "    \n",
    "    return p\n",
    "\n",
    "def serve_citation_dynamics_layout():\n",
    "    def update(b):\n",
    "        try:\n",
    "            pmid = int(text.value)\n",
    "            data = analyzer.cit_df[analyzer.cit_df['pmid'] == pmid]\n",
    "            if len(data) == 1:\n",
    "                x = data.columns[1:-1].values.astype(int)\n",
    "                y = data[x].values[0]\n",
    "                bar.data_source.data = {'x': x, 'y': y}\n",
    "            else:\n",
    "                text.value = 'Bad ID'\n",
    "            push_notebook(handle=h)\n",
    "        except ValueError:\n",
    "            text.value = ''\n",
    "\n",
    "    title = \"Number of Citations per Year\"\n",
    "\n",
    "    p = figure(tools=TOOLS, toolbar_location=\"above\", plot_width=960, plot_height = 300, title=title)\n",
    "    p.xaxis.axis_label = \"Year\"\n",
    "    p.yaxis.axis_label = \"Number of citations\"\n",
    "    p.hover.tooltips = [\n",
    "        (\"Year\", \"@x\"),\n",
    "        (\"Cited by\", \"@y paper(s) in @x\"),\n",
    "    ]\n",
    "\n",
    "    d = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "    bar = p.vbar(x='x', width=0.8, top='y', source=d, color='#A6CEE3', line_width=3)\n",
    "    \n",
    "    text = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter PMID',\n",
    "        description='PMID:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    button = widgets.Button(\n",
    "        description='Show',\n",
    "        disabled=False,\n",
    "        button_style='info',\n",
    "        tooltip='Show'\n",
    "    )\n",
    "    button.on_click(update)\n",
    "\n",
    "    panel = widgets.HBox([text, button])\n",
    "\n",
    "    display(panel)\n",
    "    h = show(p, notebook_handle=True)\n",
    "    \n",
    "    return p, h, panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:30:25.773816Z",
     "start_time": "2019-05-07T09:30:25.624908Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "NUM_MOST_COMMON = 5\n",
    "\n",
    "def get_ngrams(string):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokens = list(filter(lambda s: any(c.isalpha() for c in s), string.lower().replace(',', '').replace('.', '').split(' ')))\n",
    "    tokens = [t for t in tokens if t not in stop_words and t not in analyzer.terms]\n",
    "    ngrams = list(tokens)\n",
    "    for t1, t2 in zip(tokens[:-1], tokens[1:]):\n",
    "        ngrams.append(t1 + ' ' + t2)\n",
    "    for t1, t2, t3 in zip(tokens[:-2], tokens[1:-1], tokens[2:]):\n",
    "        ngrams.append(t1 + ' ' + t2 + ' ' + t3)\n",
    "    return ngrams\n",
    "\n",
    "def get_most_common_ngrams(titles):\n",
    "    ngrams = []\n",
    "    for title in titles:\n",
    "        ngrams.extend(get_ngrams(title))\n",
    "    most_common = {}\n",
    "    for ngram, cnt in Counter(ngrams).most_common(NUM_MOST_COMMON):\n",
    "        most_common[ngram] = cnt / len(titles)\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:31:26.889295Z",
     "start_time": "2019-05-07T09:30:25.779813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: handle queries which return more than 1000000 items\n",
      "TODO: use local database instead of PubMed API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-07 12:30:28,571 INFO: Found 2151 articles about ('single', 'cell', 'rna', 'seq')\n",
      "2019-05-07 12:30:28,572 INFO: Loading publication data\n",
      "2019-05-07 12:30:28,577 INFO: Creating pmids table for request with index.\n",
      "2019-05-07 12:31:26,871 INFO: Found 1427 publications in the local database\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1799681</td>\n",
       "      <td>Co-polymer tracts in eukaryotic, prokaryotic, ...</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7579578</td>\n",
       "      <td>The cloning and sequencing of cervine interleu...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8988377</td>\n",
       "      <td>GTG as translation initiation codon in the apo...</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10520743</td>\n",
       "      <td>Molecular cloning and characterization of a mo...</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11697148</td>\n",
       "      <td>Molecular cloning and sequence analysis of a h...</td>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title    year\n",
       "0   1799681  Co-polymer tracts in eukaryotic, prokaryotic, ...  1991.0\n",
       "1   7579578  The cloning and sequencing of cervine interleu...  1995.0\n",
       "2   8988377  GTG as translation initiation codon in the apo...  1996.0\n",
       "3  10520743  Molecular cloning and characterization of a mo...  1998.0\n",
       "4  11697148  Molecular cloning and sequence analysis of a h...  2001.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = KeyPaperAnalyzer()\n",
    "analyzer.search(*SEARCH_TERMS)\n",
    "analyzer.load_publications()\n",
    "analyzer.pub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-07 12:31:26,899 INFO: Calculating co-citations for selected articles\n"
     ]
    }
   ],
   "source": [
    "# In case this command is too long, you can stop and start DB\n",
    "# pg_ctl -D /usr/local/var/postgres stop -s -m fast\n",
    "# pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start\n",
    "analyzer.load_cocitations()\n",
    "analyzer.cocit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.769Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer.load_citation_stats()\n",
    "analyzer.cit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.782Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.merge(analyzer.pub_df, analyzer.cit_df, on='pmid')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtopics a.k.a. Clusters in the Co-citation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.798Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logging.info(f'Louvain community clustering of co-citation graph')\n",
    "p = community.best_partition(analyzer.CG)\n",
    "components = set(p.values())\n",
    "logging.info(f'Found {len(components)} components')\n",
    "# q = list(greedy_modularity_communities(analyzer.CG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.810Z"
    }
   },
   "outputs": [],
   "source": [
    "# This will limit total number of components\n",
    "GRANULARITY = 0.01\n",
    "logging.info(f'Merging components smaller than {GRANULARITY} to \"Other\" component')\n",
    "threshold = int(GRANULARITY * len(p))\n",
    "comp_sizes = {com: sum([p[node] == com for node in p.keys()]) for com in components}\n",
    "comp_to_merge = {com: comp_sizes[com] <= threshold for com in components}\n",
    "if sum(comp_to_merge.values()) > 0:\n",
    "    logging.info(f'Reassigning components')\n",
    "    pm = {}\n",
    "    newcomps = {}\n",
    "    ci = 1 # Other component is 0.\n",
    "    for k, v in p.items():\n",
    "        if comp_sizes[v] <= threshold:\n",
    "            pm[k] = 0 # Other\n",
    "            continue\n",
    "        if v not in newcomps:\n",
    "            newcomps[v] = ci\n",
    "            ci += 1\n",
    "        pm[k] = newcomps[v]\n",
    "    logging.info(f'Processed {len(set(pm.values()))} components')\n",
    "else:\n",
    "    pm = p\n",
    "components = set(pm.values())    \n",
    "pmcomp_sizes = {com: sum([pm[node] == com for node in pm.keys()]) for com in components}\n",
    "logging.info('\\n'.join([f'{k}: {v} ({int(100 * v / len(pm))}%)' for k,v in pmcomp_sizes.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.975Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "logging.info('Visualize components')\n",
    "\n",
    "G = analyzer.CG.copy()\n",
    "\n",
    "cmap = plt.cm.get_cmap('nipy_spectral', len(set(pm.values())))\n",
    "comp_palette = [RGB(*[round(c*255) for c in cmap(i)[:3]]) for i in range(len(set(pm.values())))]\n",
    "\n",
    "# set node attributes\n",
    "node_color = {node: comp_palette[pm[node]] for node in G.nodes()}\n",
    "nx.set_node_attributes(G, node_color, 'colors')\n",
    "\n",
    "# Show with Bokeh\n",
    "plot = Plot(plot_width=400, plot_height=400, x_range=Range1d(-1.1, 1.1), y_range=Range1d(-1.1, 1.1))\n",
    "plot.title.text = 'Components visualization'\n",
    "\n",
    "graph = from_networkx(G, nx.spring_layout, scale=1, center=(0, 0))\n",
    "graph.node_renderer.glyph = Circle(size=5, fill_color='colors')\n",
    "\n",
    "# add data for rendering\n",
    "graph.node_renderer.data_source.data['id'] = list(G.nodes())\n",
    "\n",
    "# add tools to the plot\n",
    "# hover,pan,tap,wheel_zoom,box_zoom,reset,save\n",
    "plot.add_tools(HoverTool(tooltips=[(\"Id\", \"@id\")]), \n",
    "               PanTool(), WheelZoomTool(), BoxZoomTool(), ResetTool(), SaveTool())\n",
    "\n",
    "plot.renderers.append(graph)\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:20.996Z"
    }
   },
   "outputs": [],
   "source": [
    "pm_ints = {int(k): v for k,v in pm.items()}\n",
    "df_comp = pd.Series(pm_ints).reset_index().rename(columns={'index': 'pmid', 0: 'comp'})\n",
    "df_all = pd.merge(df_all, df_comp, on='pmid')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.003Z"
    }
   },
   "outputs": [],
   "source": [
    "years = df_all.columns.values[3:-2].astype(int)\n",
    "min_year, max_year = np.min(years), np.max(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.013Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logging.info('Summary component detailed info visualization')\n",
    "\n",
    "n_comps = df_all['comp'].nunique()\n",
    "cmap = plt.cm.get_cmap('nipy_spectral', n_comps)\n",
    "palette = [RGB(*[round(c*255) for c in cmap(i)[:3]]) for i in range(n_comps)]\n",
    "\n",
    "components = [str(i) for i in range(n_comps)]\n",
    "years = [str(y) for y in range(min_year, max_year)]\n",
    "data = {'years': years}\n",
    "for c in range(n_comps):\n",
    "    data[str(c)] = [len(df_all[np.logical_and(df_all['comp'] == c, df_all['year'] == y)]) \\\n",
    "                    for y in range(min_year, max_year)]\n",
    "\n",
    "p = figure(x_range=years, plot_width=960, plot_height=300, title=\"Components by Year\",\n",
    "           toolbar_location=None, tools=\"hover\", tooltips=\"$name @components: @$name\")\n",
    "\n",
    "p.vbar_stack(components, x='years', width=0.9, color=palette, source=data, alpha=0.5,\n",
    "             legend=[value(c) for c in components])\n",
    "\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "p.xgrid.grid_line_color = None\n",
    "p.axis.minor_tick_line_color = None\n",
    "p.outline_line_color = None\n",
    "p.legend.location = \"top_left\"\n",
    "p.legend.orientation = \"horizontal\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.038Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logging.info('Per component detailed info visualization')\n",
    "n_comps = df_all['comp'].nunique()\n",
    "ds = [None] * n_comps\n",
    "layouts = [None] * n_comps\n",
    "most_common = [None] * n_comps\n",
    "cmap = plt.cm.get_cmap('nipy_spectral', n_comps)\n",
    "for c in range(n_comps):\n",
    "    ds[c] = build_data_source(df_all[df_all['comp'] == c])\n",
    "    most_common[c] = dict(get_most_common_ngrams(df_all[df_all['comp'] == c]['title'].values))\n",
    "    kwd = ', '.join([f'{k} ({v:.2f})' for k, v in most_common[c].items()])\n",
    "    title = f'Subtopic #{c}: {kwd}'\n",
    "    layouts[c] = serve_scatter_article_layout(ds[c], title, year_range=[min_year, max_year], \n",
    "                                              color=RGB(*[round(ch*255) for ch in cmap(c)[:3]]))\n",
    "    show(layouts[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Cited Papers Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.046Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = df_all.sort_values(by='total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.051Z"
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.1 # 10 %\n",
    "MAX_PAPERS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.062Z"
    }
   },
   "outputs": [],
   "source": [
    "print('TODO: color me by components colors')\n",
    "papers_to_show = min(MAX_PAPERS, round(len(analyzer.cit_df) * THRESHOLD))\n",
    "ds_top = build_data_source(df_all.iloc[:papers_to_show, :])\n",
    "layout_top = serve_scatter_article_layout(ds_top, 'Top cited papers', year_range=[min_year, max_year])\n",
    "show(layout_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Cited Papers for Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.074Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_gain_data = []\n",
    "cols = df_all.columns[3:-2]\n",
    "for i in range(len(cols)):\n",
    "    max_gain = df_all[cols[i]].astype(int).max()\n",
    "    if max_gain > 0:\n",
    "        sel = df_all[df_all[cols[i]] == max_gain]\n",
    "        max_gain_data.append([cols[i], sel['pmid'].values[0], \n",
    "                              sel['title'].values[0], max_gain])\n",
    "        \n",
    "max_gain_df = pd.DataFrame(max_gain_data, columns=['year', 'pmid', 'title', 'count'])\n",
    "max_gain_df.head(20)\n",
    "\n",
    "ds_max = ColumnDataSource(data=dict(year=max_gain_df['year'], pmid=max_gain_df['pmid'].astype(str),\n",
    "                                   title=max_gain_df['title'], count=max_gain_df['count']))\n",
    "factors=max_gain_df['pmid'].astype(str).unique()\n",
    "cmap = plt.cm.get_cmap('nipy_spectral', len(factors))\n",
    "palette = [RGB(*[round(c*255) for c in cmap(i)[:3]]) for i in range(len(factors))]\n",
    "colors = factor_cmap('pmid', palette=palette, factors=factors)\n",
    "\n",
    "year_range = [min_year, max_year]\n",
    "p = figure(tools=TOOLS, toolbar_location=\"above\", \n",
    "           plot_width=960, plot_height=300, x_range=year_range, title='Max gain')\n",
    "p.xaxis.axis_label = 'Year'\n",
    "p.yaxis.axis_label = 'Number of citations'\n",
    "p.hover.tooltips = [\n",
    "    (\"PMID\", '@pmid'),\n",
    "    (\"Title\", '@title'),\n",
    "    (\"Year\", '@year'),\n",
    "    (\"Cited by\", '@count papers in @year')\n",
    "]\n",
    "\n",
    "p.vbar(x='year', width=0.8, top='count', fill_alpha=0.5, source=ds_max, fill_color=colors, line_color=colors)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation per Year Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.124Z"
    }
   },
   "outputs": [],
   "source": [
    "p, h, panel = serve_citation_dynamics_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.135Z"
    }
   },
   "outputs": [],
   "source": [
    "cocit_df = analyzer.cocit_df.copy()\n",
    "min_year = cocit_df['year'].min().astype(int)\n",
    "max_year = cocit_df['year'].max().astype(int)\n",
    "print(f'Cocitation year range: {min_year} - {max_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.143Z"
    }
   },
   "outputs": [],
   "source": [
    "YEAR_STEP = 2\n",
    "\n",
    "evolution_series = []\n",
    "year_range = range(max_year, min_year-1, -YEAR_STEP)\n",
    "print('Filtering top 10000 or 80% of all the co-citations')\n",
    "for year in range(max_year, min_year-1, -YEAR_STEP):   \n",
    "    cocit_grouped_df = cocit_df[cocit_df['year'] <= year].groupby(['cited_1', 'cited_2', 'year']).count().reset_index()\n",
    "    cocit_grouped_df = cocit_grouped_df.pivot_table(index=['cited_1', 'cited_2'], \n",
    "                                                    columns=['year'], values=['citing']).reset_index()\n",
    "    cocit_grouped_df = cocit_grouped_df.replace(np.nan, 0)\n",
    "    cocit_grouped_df['total'] = cocit_grouped_df.iloc[:, 2:].sum(axis=1)\n",
    "    cocit_grouped_df = cocit_grouped_df.sort_values(by='total', ascending=False)\n",
    "    cocit_grouped_df = cocit_grouped_df.iloc[:min(10000, round(0.8 * len(cocit_grouped_df))), :]\n",
    "    \n",
    "    CG = nx.Graph()\n",
    "    # NOTE: we use nodes id as String to avoid problems str keys in jsonify during graph visualization\n",
    "    for el in cocit_grouped_df[['cited_1', 'cited_2', 'total']].values.astype(int):\n",
    "        CG.add_edge(str(el[0]), str(el[1]), weight=el[2])\n",
    "    print(f'{year} - {len(CG.nodes)} nodes, {len(CG.edges)} edges') \n",
    "    \n",
    "    p = {int(vertex): int(comp) for vertex, comp in community.best_partition(CG).items()}\n",
    "    evolution_series.append(pd.Series(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.154Z"
    }
   },
   "outputs": [],
   "source": [
    "SHIFT = True # use random shift to see trace of separate articles\n",
    "FILLNA = True # NaN values sometimes cause KeyError while plotting, but sometimes not (?!)\n",
    "\n",
    "evolution_df = pd.concat(evolution_series, axis=1).rename(columns=dict(enumerate(year_range)))\n",
    "evolution_df['current'] = evolution_df[max_year]\n",
    "evolution_df = evolution_df[list(reversed(list(evolution_df.columns)))]\n",
    "\n",
    "if SHIFT:\n",
    "    shift = np.random.uniform(0.25, 0.75, size=(len(evolution_df),))\n",
    "    for year in year_range:\n",
    "        evolution_df[year] += shift\n",
    "        \n",
    "if FILLNA:\n",
    "    evolution_df = evolution_df.fillna(-1.0)\n",
    "\n",
    "evolution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-07T09:30:21.161Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "pd.plotting.parallel_coordinates(evolution_df, 'current', sort_labels=True)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Component ID')\n",
    "plt.grid(b=True, which='both', linestyle='--')\n",
    "plt.legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
