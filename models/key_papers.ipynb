{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key papers\n",
    "\n",
    "**TOPICS OF INTEREST** - from the meeting in January\n",
    "\n",
    "* inflammation aging chronic (2004) - 13k papers\n",
    "* genome editing / manipulation, CRISPR - 13k papers\n",
    "* induced stem cells - 73k papers - 3h for calculating co-citations\n",
    "* single-cell sequencing (2012) - 3k papers\n",
    "* ATAC-seq (2015) - 276 papers\n",
    "* immunomodulation cancer - 71k papers\n",
    "* Telomere Theories of Aging - ??\n",
    "* mTOR pathway - 14255\n",
    "* autophagy - ??\n",
    "* Calorie restriction - 3933\n",
    "\n",
    "Complement Factor H + Age-Related Mascular Degeneration - investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file with citation stats is required to run several cells of this notebook successfully.\n",
    "The file can be obtained with the following commands if user has access to `pubmed` database (use crawler).\n",
    "\n",
    "1. Run `psql`.\n",
    "2. Run following commands in the `psql` prompt:\n",
    "    * `\\f ','`\n",
    "    * `\\a`\n",
    "    * `\\t`\n",
    "    * `\\o '/path/to/the/file'`\n",
    "    * `SELECT C.pmid_cited AS pmid, P.year, COUNT(1) AS count`\n",
    "    * `FROM Citations C`\n",
    "    * `JOIN Publications P`\n",
    "    * `ON C.pmid_citing = P.pmid`\n",
    "    * `GROUP BY C.pmid_cited, P.year;`\n",
    "    * `\\o`\n",
    "3. Store `/path/to/the/file` in the `CITATION_STATS_FILE` variable in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issues**:\n",
    "\n",
    "1. Some information in tooltips with long titles may occur out of plot bounds.\n",
    "2. How should I place articles with the same year? (currently y-axis position is random in [0,1]...)\n",
    "3. Some research on clustering algorithms is needed! (also `networkx.algorithms.community`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**:\n",
    "\n",
    "1. Subtopic Analysis based on co-citation graph clustering\n",
    "2. Top Cited Papers detection (overall and for certain year)\n",
    "3. Citation Dynamics for a certain article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_TERMS = ['human', 'aging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "\n",
    "import gc\n",
    "import ipywidgets as widgets\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg_driver\n",
    "\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.models import ColumnDataSource, LabelSet, OpenURL, TapTool, CustomJS\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = 'nikolay.kapralov@gmail.com'\n",
    "PUBMED_ARTICLE_BASE_URL = 'https://www.ncbi.nlm.nih.gov/pubmed/?term='\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', level=logging.DEBUG)\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyPaperAnalyzer:       \n",
    "    def __init__(self):\n",
    "        self.conn = pg_driver.connect(dbname='pubmed', user='biolabs', password='pubtrends', host='localhost')\n",
    "        self.cursor = self.conn.cursor()\n",
    "        \n",
    "    def load_publications(self):\n",
    "        logging.info('Loading publication data')\n",
    "        \n",
    "        query = '''\n",
    "        SELECT pmid, title, year\n",
    "        FROM Publications\n",
    "        WHERE pmid = ANY(%s);\n",
    "        '''\n",
    "        \n",
    "        with self.conn:\n",
    "            self.cursor.execute(query, (self.pmids,))\n",
    "        pub_data = []\n",
    "        for row in self.cursor:\n",
    "            pub_data.append(list(row))\n",
    "        self.pub_df = pd.DataFrame(pub_data, columns=['pmid', 'title', 'year'])\n",
    "        logging.info(f'Found {len(self.pub_df)} publications in the local database')\n",
    "            \n",
    "    def load_cocitations(self):\n",
    "        logging.info('Calculating co-citations for selected articles')\n",
    "\n",
    "        query = '''\n",
    "        SELECT C1.pmid_citing, C1.pmid_cited, C2.pmid_cited, P.year\n",
    "        FROM Citations C1\n",
    "        JOIN Citations C2\n",
    "        ON C1.pmid_citing = C2.pmid_citing AND C1.pmid_cited < C2.pmid_cited\n",
    "        JOIN Publications P\n",
    "        ON C1.pmid_citing = P.pmid\n",
    "        WHERE C1.pmid_cited = ANY(%s) AND C2.pmid_cited = ANY(%s)\n",
    "        LIMIT 10000;\n",
    "        '''\n",
    "        print(\"TODO: Remove LIMIT 10000\")\n",
    "\n",
    "        with self.conn:\n",
    "            self.cursor.execute(query, (self.pmids, self.pmids,))\n",
    "            \n",
    "        cocit_data = []\n",
    "        for row in self.cursor:\n",
    "            cocit_data.append(list(row))\n",
    "        self.cocit_df = pd.DataFrame(cocit_data, columns=['citing', 'cited_1', 'cited_2', 'year'])\n",
    "        logging.info(f'Found {len(self.cocit_df)} co-cited pairs of articles')\n",
    "        \n",
    "        self.cocit_grouped_df = self.cocit_df.groupby(['cited_1', 'cited_2', 'year']).count().reset_index()\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.pivot_table(index=['cited_1', 'cited_2'], \n",
    "                                                          columns=['year'], values=['citing']).reset_index()\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.replace(np.nan, 0)\n",
    "        self.cocit_grouped_df['total'] = self.cocit_grouped_df.iloc[:, 2:].sum(axis=1)\n",
    "        self.cocit_grouped_df = self.cocit_grouped_df.sort_values(by='total', ascending=False)\n",
    "        \n",
    "        self.CG = nx.Graph()\n",
    "        for el in analyzer.cocit_grouped_df[['cited_1', 'cited_2', 'total']].values.astype(int):\n",
    "            self.CG.add_edge(el[0], el[1], weight=el[2])\n",
    "\n",
    "    def load_citation_stats(self, cit_stats_file):        \n",
    "        logging.info('Started loading citation stats')\n",
    "        self.cit_df = pd.read_csv(cit_stats_file, names=['pmid', 'year', 'count']).fillna(0)\n",
    "        logging.info('Done loading citation stats')\n",
    "\n",
    "        # XXX Using set here improves performance drastically!\n",
    "        pmids_set = set(self.pmids)\n",
    "        self.cit_df = self.cit_df.loc[np.logical_and([i in pmids_set for i in self.cit_df['pmid']], \n",
    "                                                     self.cit_df['year'] > 0)]\n",
    "        logging.info('Done filtering')\n",
    "\n",
    "        self.cit_df[['pmid']] = self.cit_df[['pmid']].applymap(np.uint32)\n",
    "        self.cit_df[['year', 'count']] = self.cit_df[['year', 'count']].applymap(np.uint16)\n",
    "        logging.info('Done transformation')\n",
    "\n",
    "        self.cit_df = self.cit_df.pivot(index='pmid', columns='year', values='count').reset_index().replace(np.nan, 0)\n",
    "        self.cit_df['total'] = self.cit_df.iloc[:, 1:].sum(axis = 1)\n",
    "        self.cit_df = self.cit_df.sort_values(by='total', ascending=False)\n",
    "        logging.info('Done aggregation')\n",
    "        \n",
    "        logging.info(f\"Loaded citation stats for {len(self.cit_df)} of {len(self.pmids)} articles. \" +\n",
    "                    \"Others may either have zero citations or be absent in the local database.\")\n",
    "\n",
    "            \n",
    "    def plot_total_citations(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        ax = self.cit_df['total'].plot.bar()\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xlabel('Articles')\n",
    "        ax.set_ylabel('Number of citations')\n",
    "    \n",
    "    def search(self, *terms):\n",
    "        print('TODO: handle queries which return more than 100000 items')\n",
    "        print('TODO: use local database instead of PubMed API')\n",
    "        self.terms = [t.lower() for t in terms]\n",
    "        query=' '.join(terms)\n",
    "        handle = Entrez.esearch(db='pubmed', retmax='100000', retmode='xml', term=query)\n",
    "        self.pmids = [int(pmid) for pmid in Entrez.read(handle)['IdList']]\n",
    "        logging.info(f'Found {len(self.pmids)} articles about {terms}')       \n",
    "        \n",
    "    def top_cited_papers(self, threshold=0.05):\n",
    "        ids = self.cit_df.iloc[:round(len(self.cit_df) * threshold), 0].values\n",
    "        counts = self.cit_df.iloc[:round(len(self.cit_df) * threshold), -1].values\n",
    "        urls = [PUBMED_ARTICLE_BASE_URL + str(i) for i in ids]\n",
    "        return zip(ids, urls, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_source(df):\n",
    "    # TODO: use d = ColumnDataSource(df)\n",
    "    d = ColumnDataSource(data=dict(pmid=df['pmid'], title=df['title'], year=df['year'], total=df['total'],\n",
    "                                   size=np.log(df['total']) / 10, pos=np.random.random(size=len(df))))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = \"hover,pan,tap,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "def serve_scatter_article_layout(source, title, year_range=None):\n",
    "    callback = CustomJS(args=dict(source=source, base=PUBMED_ARTICLE_BASE_URL), code=\"\"\"\n",
    "        var data = source.data, selected = source.selected.indices;\n",
    "        if (selected.length == 1) {\n",
    "            // only consider case where one glyph is selected by user\n",
    "            selected_id = data['pmid'][selected[0]]\n",
    "            for (var i = 0; i < data['pmid'].length; ++i){\n",
    "                if(data['pmid'][i] == selected_id){\n",
    "                    window.open(base + data['pmid'][i], '_blank');\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\")\n",
    "\n",
    "    p = figure(tools=TOOLS, toolbar_location=\"above\", plot_width=960, plot_height=400, x_range=year_range, title=title)\n",
    "    p.xaxis.axis_label = 'Year'\n",
    "    p.hover.tooltips = [\n",
    "        (\"PMID\", '@pmid'),\n",
    "        (\"Title\", '@title'),\n",
    "        (\"Year\", '@year'),\n",
    "        (\"Cited by\", '@total paper(s) total')\n",
    "    ]\n",
    "    p.js_on_event('tap', callback)\n",
    "\n",
    "    p.circle(x='year', y='pos', fill_alpha=0.2, source=source, radius='size')\n",
    "    \n",
    "    return p\n",
    "\n",
    "def serve_citation_dynamics_layout():\n",
    "    def update(b):\n",
    "        try:\n",
    "            pmid = int(text.value)\n",
    "            data = analyzer.cit_df[analyzer.cit_df['pmid'] == pmid]\n",
    "            if len(data) == 1:\n",
    "                x = data.columns[1:-1].values.astype(int)\n",
    "                y = data[x].values[0]\n",
    "                bar.data_source.data = {'x': x, 'y': y}\n",
    "            else:\n",
    "                text.value = 'Bad ID'\n",
    "            push_notebook(handle=h)\n",
    "        except ValueError:\n",
    "            text.value = ''\n",
    "\n",
    "    title = \"Number of Citations per Year\"\n",
    "\n",
    "    p = figure(tools=TOOLS, toolbar_location=\"above\", plot_width=960, plot_height = 300, title=title)\n",
    "    p.xaxis.axis_label = \"Year\"\n",
    "    p.yaxis.axis_label = \"Number of citations\"\n",
    "    p.hover.tooltips = [\n",
    "        (\"Year\", \"@x\"),\n",
    "        (\"Cited by\", \"@y paper(s) in @x\"),\n",
    "    ]\n",
    "\n",
    "    d = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "    bar = p.vbar(x='x', width=0.8, top='y', source=d, color='#A6CEE3', line_width=3)\n",
    "    \n",
    "    text = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter PMID',\n",
    "        description='PMID:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    button = widgets.Button(\n",
    "        description='Show',\n",
    "        disabled=False,\n",
    "        button_style='info',\n",
    "        tooltip='Show'\n",
    "    )\n",
    "    button.on_click(update)\n",
    "\n",
    "    panel = widgets.HBox([text, button])\n",
    "\n",
    "    display(panel)\n",
    "    h = show(p, notebook_handle=True)\n",
    "    \n",
    "    return p, h, panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "NUM_MOST_COMMON = 5\n",
    "\n",
    "def get_ngrams(string):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokens = list(filter(lambda s: any(c.isalpha() for c in s), string.lower().replace(',', '').replace('.', '').split(' ')))\n",
    "    tokens = [t for t in tokens if t not in stop_words and t not in analyzer.terms]\n",
    "    ngrams = list(tokens)\n",
    "    for t1, t2 in zip(tokens[:-1], tokens[1:]):\n",
    "        ngrams.append(t1 + ' ' + t2)\n",
    "    for t1, t2, t3 in zip(tokens[:-2], tokens[1:-1], tokens[2:]):\n",
    "        ngrams.append(t1 + ' ' + t2 + ' ' + t3)\n",
    "    return ngrams\n",
    "\n",
    "def get_most_common_ngrams(titles):\n",
    "    ngrams = []\n",
    "    for title in titles:\n",
    "        ngrams.extend(get_ngrams(title))\n",
    "    most_common = {}\n",
    "    for ngram, cnt in Counter(ngrams).most_common(NUM_MOST_COMMON):\n",
    "        most_common[ngram] = cnt / len(titles)\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = KeyPaperAnalyzer()\n",
    "analyzer.search(*SEARCH_TERMS)\n",
    "analyzer.load_publications()\n",
    "analyzer.pub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case this command is too long, you can stop and start DB\n",
    "# pg_ctl -D /usr/local/var/postgres stop -s -m fast\n",
    "# pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start\n",
    "analyzer.load_cocitations()\n",
    "analyzer.cocit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.load_citation_stats(cit_stats_file='../citations_per_year.csv')\n",
    "analyzer.cit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(analyzer.pub_df, analyzer.cit_df, on='pmid')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtopics a.k.a. Clusters in the Co-citation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "\n",
    "p = community.best_partition(analyzer.CG)\n",
    "# q = list(greedy_modularity_communities(analyzer.CG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.Series(p).reset_index().rename(columns={'index': 'pmid', 0: 'comp'})\n",
    "df_all = pd.merge(df_all, df_comp, on='pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df_all.columns.values[3:-2].astype(int)\n",
    "min_year, max_year = np.min(years), np.max(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_comps = df_all['comp'].nunique()\n",
    "ds = [None] * n_comps\n",
    "layouts = [None] * n_comps\n",
    "most_common = [None] * n_comps\n",
    "for c in range(n_comps):\n",
    "    ds[c] = build_data_source(df_all[df_all['comp'] == c])\n",
    "    most_common[c] = dict(get_most_common_ngrams(df_all[df_all['comp'] == c]['title'].values))\n",
    "    kwd = ', '.join([f'{k} ({v:.2f})' for k, v in most_common[c].items()])\n",
    "    title = f'Subtopic #{c + 1}: {kwd}'\n",
    "    layouts[c] = serve_scatter_article_layout(ds[c], title, year_range=[min_year, max_year])\n",
    "    show(layouts[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Cited Papers Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.sort_values(by='total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.1 # 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_top = build_data_source(df_all.iloc[:round(len(analyzer.cit_df) * THRESHOLD), :])\n",
    "layout_top = serve_scatter_article_layout(ds_top, 'Top cited papers', year_range=[min_year, max_year])\n",
    "show(layout_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Cited Papers for Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.palettes import Category10\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "max_gain_data = []\n",
    "cols = df_all.columns[3:-2]\n",
    "for i in range(len(cols)):\n",
    "    max_gain = df_all[cols[i]].astype(int).max()\n",
    "    if max_gain > 0:\n",
    "        sel = df_all[df_all[cols[i]] == max_gain]\n",
    "        max_gain_data.append([cols[i], sel['pmid'].values[0], \n",
    "                              sel['title'].values[0], max_gain])\n",
    "        \n",
    "max_gain_df = pd.DataFrame(max_gain_data, columns=['year', 'pmid', 'title', 'count'])\n",
    "max_gain_df.head(20)\n",
    "\n",
    "ds_max = ColumnDataSource(data=dict(year=max_gain_df['year'], pmid=max_gain_df['pmid'].astype(str),\n",
    "                                   title=max_gain_df['title'], count=max_gain_df['count']))\n",
    "colors = factor_cmap('pmid', palette=Category10[10], factors=max_gain_df['pmid'].astype(str).unique())\n",
    "\n",
    "year_range = [1985, 2019]\n",
    "p = figure(tools=TOOLS, toolbar_location=\"above\", plot_width=960, plot_height=300, x_range=year_range, title='Max gain')\n",
    "p.xaxis.axis_label = 'Year'\n",
    "p.yaxis.axis_label = 'Number of citations'\n",
    "p.hover.tooltips = [\n",
    "    (\"PMID\", '@pmid'),\n",
    "    (\"Title\", '@title'),\n",
    "    (\"Year\", '@year'),\n",
    "    (\"Cited by\", '@count papers in @year')\n",
    "]\n",
    "\n",
    "p.vbar(x='year', width=0.8, top='count', fill_alpha=0.2, source=ds_max, fill_color=colors, line_color=colors)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation per Year Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, h, panel = serve_citation_dynamics_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
