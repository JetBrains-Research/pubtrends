{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pubtrends\n",
    "\n",
    "This Jupyter Notebook can be used to perform basic publication analysis.\n",
    "\n",
    "**IMPORTANT** \n",
    "Turn on experimental features in config file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "1. Define the `SEARCH_QUERY` variable in the cell below with a list of keywords that describe the science branch of your interest.\n",
    "2. Run all cells & see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEARCH_QUERY = 'human aging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "from bokeh.plotting import show, output_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from pysrc.papers.config import PubtrendsConfig\n",
    "from pysrc.papers.db.pm_postgres_loader import PubmedPostgresLoader\n",
    "from pysrc.papers.db.ss_postgres_loader import SemanticScholarPostgresLoader\n",
    "from pysrc.papers.analyzer import PapersAnalyzer\n",
    "from pysrc.papers.plot.plotter import Plotter\n",
    "from pysrc.papers.utils import SORT_MOST_CITED, SORT_MOST_RECENT, cut_authors_list\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "output_notebook()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEARCH_SORT = SORT_MOST_CITED\n",
    "SEARCH_PAPERS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = PubtrendsConfig(test=False)\n",
    "config.feature_evolution_enabled = True\n",
    "loader = PubmedPostgresLoader(config)\n",
    "analyzer = PapersAnalyzer(loader, config)\n",
    "try:\n",
    "    ids = analyzer.search_terms(SEARCH_QUERY, limit=SEARCH_PAPERS, sort=SEARCH_SORT)\n",
    "    analyzer.analyze_papers(ids, SEARCH_QUERY)\n",
    "finally:\n",
    "    loader.close_connection()\n",
    "    analyzer.teardown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotter = Plotter(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.papers_by_year())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pysrc.papers.analysis.text import get_frequent_tokens, get_topic_word_cloud_data\n",
    "\n",
    "freq_kwds = get_frequent_tokens(analyzer.top_cited_df, query=analyzer.query)\n",
    "wc, _ = plotter.papers_word_cloud_and_callback(freq_kwds)\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.top_cited_papers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.most_cited_per_year_papers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.fastest_growth_per_year_papers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single paper citations dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.paper_citations_per_year(analyzer.df, analyzer.df['id'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics a.k.a. Clusters in the Co-citation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.topic_years_distribution())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.heatmap_topics_similarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show(plotter.topics_hierarchy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First cluster papers\n",
    "show(plotter.topics_info_and_word_cloud_and_callback()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent keywords timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pysrc.papers.analysis.text import get_frequent_tokens\n",
    "freq_kwds = get_frequent_tokens(analyzer.top_cited_df, query=analyzer.query)\n",
    "show(plotter.plot_keywords_frequencies(freq_kwds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pysrc.papers.analysis.metadata import popular_authors, popular_journals, build_authors_similarity_graph, \\\n",
    "    compute_authors_citations_and_papers, cluster_authors\n",
    "\n",
    "logging.info(\"Analyzing groups of similar authors\")\n",
    "authors_citations, authors_papers = compute_authors_citations_and_papers(analyzer.df)\n",
    "author_productivity = {a: np.log1p(authors_citations.get(a, 1)) * p\n",
    "                            for a, p in authors_papers.items()}\n",
    "min_author_productivity = np.percentile(list(author_productivity.values()), 95)\n",
    "min_author_productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "authors_similarity_graph = build_authors_graph(\n",
    "    analyzer.df, analyzer.texts_similarity, analyzer.citations_graph, \n",
    "    analyzer.cocit_grouped_df, analyzer.bibliographic_coupling_df,\n",
    "    lambda a: author_productivity[a] >= min_author_productivity\n",
    ")\n",
    "logging.info(f'Built authors graph - {len(authors_graph.nodes())} nodes and {len(authors_graph.edges())} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "authors_clusters = cluster_authors(authors_similarity_graph, analyzer.similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plotter.authors_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AUTHORS_PER_COMP = 20\n",
    "group_authors = {}\n",
    "top_authors = set([])\n",
    "for group in sorted(set(authors_clusters.values())):\n",
    "    authors = [a for a in authors_clusters.keys() if authors_clusters[a] == group]\n",
    "    authors.sort(key=lambda a: author_productivity[a], reverse=True)\n",
    "    top = authors[:TOP_CITED_AUTHORS_PER_COMP]\n",
    "    top_authors.update(top)\n",
    "    group_authors[group] = \", \".join(top)\n",
    "    print(f'#{group} ({len(authors)}) {\", \".join(top)}' + (', ...' if len(authors) > AUTHORS_PER_COMP else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papers per group of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_groups = np.zeros(shape=(len(analyzer.df), len(set(authors_clusters.values()))))\n",
    "for i, row in analyzer.df[['authors']].iterrows():\n",
    "    for a in row[0].split(', '):\n",
    "        if a in authors_clusters:\n",
    "            group = authors_clusters[a]\n",
    "            paper_groups[i, group] += 1 / part_sizes[group]\n",
    "groups = np.argmax(paper_groups, axis=1)\n",
    "papers_assigned = paper_groups.sum(axis=1) > 0\n",
    "groups_partition = {pid: groups[i] for i, pid in enumerate(analyzer.df['id']) if papers_assigned[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_part_sizes = {c: sum([groups_partition[node] == c for node in groups_partition.keys()]) \n",
    "                     for c in set(groups_partition.values())}\n",
    "logging.info(f'Components: {groups_part_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pid, gp in groups_partition.items():\n",
    "#     if groups_part_sizes[gp] < 10:\n",
    "#         groups_partition[pid] = -1  # Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysrc.papers.analysis.topics import get_topics_description\n",
    "\n",
    "groups_pids = pd.DataFrame(groups_partition.items(), columns=['id', 'comp']). \\\n",
    "                groupby('comp')['id'].apply(list).to_dict()\n",
    "groups_description = get_topics_description(\n",
    "    analyzer.df.iloc[np.flatnonzero(papers_assigned), :], groups_pids,\n",
    "    corpus_terms, corpus_counts[np.flatnonzero(papers_assigned), :],\n",
    "    query=analyzer.query,\n",
    "    n_words=analyzer.TOPIC_DESCRIPTION_WORDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = pd.DataFrame(columns=['group', 'authors', 'papers', 'keywords'])\n",
    "for g, pids in groups_pids.items():\n",
    "    if g in group_authors and g in groups_description:\n",
    "        groups_df.loc[len(groups_df)] = (g, group_authors[g], len(pids), \n",
    "                                         ', '.join(v[0] for v in groups_description[g][:10]))\n",
    "\n",
    "display(groups_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evolution_data, keywords_data = plotter.topic_evolution()\n",
    "show(evolution_data)\n",
    "print(keywords_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank for Citation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Apply PageRank algorithm with damping factor of 0.5\n",
    "pr_nx = nx.pagerank(analyzer.citations_graph, alpha=0.5, tol=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ancestor = dict.fromkeys(analyzer.citations_graph, (0, 0))\n",
    "\n",
    "# Select ancestor with highest PR for each node\n",
    "for v in analyzer.citations_graph:\n",
    "    for u in analyzer.citations_graph[v]:\n",
    "        anc, pr = ancestor[u]\n",
    "        if pr_nx[v] > pr:\n",
    "            ancestor[u] = (v, pr_nx[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PRG = nx.DiGraph()\n",
    "for v, anc in ancestor.items():\n",
    "    u, pr = anc\n",
    "    if pr > 0:\n",
    "        PRG.add_edge(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start, end = zip(*list(PRG.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GraphRenderer, StaticLayoutProvider, Circle, HoverTool, MultiLine\n",
    "from bokeh.models.graphs import NodesAndLinkedEdges\n",
    "\n",
    "node_indices = list(filter(lambda node: len(analyzer.df[analyzer.df['id'] == node]) > 0, list(PRG.nodes())))\n",
    "\n",
    "years = []\n",
    "year_counts = {}\n",
    "titles = []\n",
    "pageranks = []\n",
    "size = []\n",
    "for node in node_indices:\n",
    "    sel = analyzer.df[analyzer.df['id'] == node]\n",
    "    year = sel['year'].values[0]\n",
    "    \n",
    "    if not year in year_counts:\n",
    "        year_counts[year] = 1\n",
    "    else:\n",
    "        year_counts[year] += 1\n",
    "    years.append(year)\n",
    "    \n",
    "    titles.append(sel['title'].values[0])\n",
    "    pageranks.append(pr_nx[node] * 100)\n",
    "    size.append(pr_nx[node] * 1000)\n",
    "max_year_count = max(list(year_counts.values()))\n",
    "min_year, max_year = min(years), max(years)\n",
    "\n",
    "plot = figure(title=\"PageRank applied to citation filtering\", \n",
    "              x_range=(min_year - 1, max_year+1), y_range=(0, max_year_count + 1),\n",
    "              tools=\"\", toolbar_location=None)\n",
    "\n",
    "TOOLTIPS = \"\"\"\n",
    "    <div style=\"max-width: 320px\">\n",
    "        <div>\n",
    "            <span style=\"font-size: 12px; font-weight: bold;\">@title</span>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style=\"font-size: 11px;\">Year</span>\n",
    "            <span style=\"font-size: 10px;\">@year</span>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style=\"font-size: 11px;\">PMID</span>\n",
    "            <span style=\"font-size: 10px;\">@id</span>\n",
    "        </div>\n",
    "        <div>\n",
    "            <span style=\"font-size: 11px;\">PageRank</span>\n",
    "            <span style=\"font-size: 10px;\">@pagerank</span>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=TOOLTIPS))\n",
    "\n",
    "graph = GraphRenderer()\n",
    "\n",
    "graph.node_renderer.data_source.add(node_indices, 'index')\n",
    "graph.node_renderer.data_source.data['id'] = node_indices\n",
    "graph.node_renderer.data_source.data['year'] = years\n",
    "graph.node_renderer.data_source.data['title'] = titles\n",
    "graph.node_renderer.data_source.data['pagerank'] = pageranks\n",
    "graph.node_renderer.data_source.data['size'] = size\n",
    "# graph.edge_renderer.data_source.data = dict(start=start, end=end)\n",
    "\n",
    "### start of layout code   \n",
    "x = [analyzer.df[analyzer.df['id'] == pmid]['year'].values[0] for pmid in node_indices]\n",
    "y = []\n",
    "tmp_year_counts = {}\n",
    "for node in node_indices:\n",
    "    year = analyzer.df[analyzer.df['id'] == node]['year'].values[0]\n",
    "    if not year in tmp_year_counts:\n",
    "        tmp_year_counts[year] = 1\n",
    "    else:\n",
    "        tmp_year_counts[year] += 1\n",
    "    y.append(tmp_year_counts[year])\n",
    "\n",
    "graph_layout = dict(zip(node_indices, zip(x, y)))\n",
    "graph.layout_provider = StaticLayoutProvider(graph_layout=graph_layout)\n",
    "\n",
    "graph.node_renderer.glyph = Circle(size='size', fill_color='blue')\n",
    "graph.node_renderer.hover_glyph = Circle(size='size', fill_color='green')\n",
    "\n",
    "# graph.edge_renderer.glyph = MultiLine(line_color='black', line_alpha=1, line_width=1)\n",
    "# graph.edge_renderer.hover_glyph = MultiLine(line_color='green', line_width=2)\n",
    "\n",
    "graph.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "plot.min_border_left = 75\n",
    "plot.renderers.append(graph)\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Papers by PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for pmid, pagerank in sorted(pr_nx.items(), key=lambda el: el[1], reverse=True)[:10]:\n",
    "    print(f\"{(100*pagerank):.2f} {analyzer.df[analyzer.df['id'] == pmid]['title'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank and citation ranking correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "analyzer.df['citation_rank'] = analyzer.df['total'].rank(method='first', ascending=False)\n",
    "pagerank_rank = sorted(pr_nx.items(), key=lambda el: el[1], reverse=True)\n",
    "\n",
    "r = np.zeros((len(pagerank_rank), 2))\n",
    "for i, (pmid, pr) in enumerate(pagerank_rank):\n",
    "    sel = analyzer.df[analyzer.df['id'] == pmid]\n",
    "    if len(sel) > 0:\n",
    "        r[i, 0] = i\n",
    "        r[i, 1] = int(sel['citation_rank'].values[0])\n",
    "        \n",
    "TOP_X = [5, 10, 30, 50, 100]\n",
    "for x in TOP_X:\n",
    "    rho, _ = spearmanr(r[:x, 0], r[:x, 1])\n",
    "    print(f'Spearman correlation coefficient for top {x}: {rho}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Very slow!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "adj = np.zeros((analyzer.similarity_graph.number_of_nodes(), analyzer.df['comp'].nunique()))\n",
    "w = np.zeros(adj.shape)\n",
    "\n",
    "for i, v in enumerate(analyzer.similarity_graph.nodes()):\n",
    "    for u in analyzer.similarity_graph[v]:\n",
    "        c = analyzer.df[analyzer.df['id'] == u]['comp'].values[0]\n",
    "        adj[i][c] += 1\n",
    "        w[i][c] += analyzer.similarity_graph[v][u]['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "size = 10\n",
    "\n",
    "hub_indices = np.argsort(np.sum(adj > 0, axis=1))[-size:]\n",
    "\n",
    "nodes_list = list(analyzer.similarity_graph.nodes)\n",
    "hub_pmids = [nodes_list[idx] for idx in hub_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Hub nodes')\n",
    "print(analyzer.df[analyzer.df['id'].isin(hub_pmids)][['id', 'title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
