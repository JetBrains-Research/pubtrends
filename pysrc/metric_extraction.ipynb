{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Extraction\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. Spacy: `conda install -c conda-forge spacy`\n",
    "2. English corpus for spacy: `python -m spacy download en_core_web_sm`\n",
    "3. text2num: `pip install text2num`\n",
    "\n",
    "### Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source Selection\n",
    "\n",
    "### Option 1: Use Search Terms \n",
    "\n",
    "1. Define the `SEARCH_QUERY` variable in the cell below with a list of keywords that describe the science branch of your interest.\n",
    "2. Set `USE_PUBMED_IMPORT` to `False`.\n",
    "\n",
    "### Option 2: Import Search Results from Pubmed \n",
    "\n",
    "1. Set `USE_PUBMED_IMPORT` to `True`.\n",
    "2. Search for terms of interest on the Pubmed website. Use Save with Selection=All Results and Format=PMID to obtain a .txt file with PMIDs of all papers that were found.\n",
    "3. Use widget below to upload a file with IDs from Pubmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 - Use Search Terms\n",
    "SEARCH_QUERY = 'zebrafish toxicity'\n",
    "\n",
    "# Option 2 - Import Search Results from Pubmed\n",
    "USE_PUBMED_IMPORT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PMIDs from Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if USE_PUBMED_IMPORT:\n",
    "    w = widgets.FileUpload(accept='.txt', multiple=False)\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Publication Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T11:13:45.558630Z",
     "start_time": "2019-05-20T11:13:20.941831Z"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import show, output_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pysrc.papers.config import PubtrendsConfig\n",
    "from pysrc.papers.progress import Progress\n",
    "from pysrc.papers.db.loaders import Loaders\n",
    "from pysrc.papers.analyzer import KeyPaperAnalyzer\n",
    "from pysrc.papers.analyzer_experimental import ExperimentalAnalyzer\n",
    "from pysrc.papers.plot.plotter_experimental import ExperimentalPlotter\n",
    "from pysrc.papers.utils import SORT_MOST_CITED, SORT_MOST_RELEVANT, SORT_MOST_RECENT, cut_authors_list\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "output_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "SEARCH_SORT = SORT_MOST_CITED\n",
    "SEARCH_PAPERS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T12:00:33.794284Z",
     "start_time": "2019-05-20T11:13:45.591588Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = PubtrendsConfig(test=False)\n",
    "loader = Loaders.get_loader('Pubmed', config)\n",
    "try:\n",
    "    if USE_PUBMED_IMPORT:\n",
    "        logging.info('Loading from file')\n",
    "        filename = list(w.value.keys())[0]\n",
    "        ids = [int(chunk) for chunk in w.value[filename]['content'].decode('utf-8').split('\\r\\n')]\n",
    "    else:\n",
    "        logging.info('Searching')\n",
    "        ids = loader.search(SEARCH_QUERY, limit=SEARCH_PAPERS, sort=SEARCH_SORT, noreviews=True)\n",
    "        ids = KeyPaperAnalyzer(loader, config).expand_ids(\n",
    "            ids, limit=int(1.2 * SEARCH_PAPERS), keep_keywords=True, steps=2\n",
    "        )\n",
    "    pub_df = loader.load_publications(ids)\n",
    "finally:\n",
    "    loader.close_connection()\n",
    "    logging.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Function for Metric Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "from spacy import displacy\n",
    "from text_to_num import alpha2digit\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "NUMBER = re.compile(r'-?[\\d]+([\\.,][\\d]+)?([eE][+-]?\\d+)?')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_candidate(metrics, token, value, idx):\n",
    "    tt = token.text\n",
    "    if tt != '%' and token.pos_ in set(['NOUN', 'PROPN']):\n",
    "        tt = lemmatizer.lemmatize(tt)\n",
    "        if tt not in metrics:\n",
    "            metrics[tt] = []\n",
    "        metrics[tt].append((value, idx))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process_number(token, value, idx, metrics):\n",
    "    logging.info(f'Number: {value}')\n",
    "    if token.head.pos_ == 'NUM':\n",
    "        tht = token.head.text\n",
    "        if tht == 'hundred':\n",
    "            value *= 100\n",
    "        elif tht == 'thousand':\n",
    "            value *= 1000\n",
    "        elif tht == 'million':\n",
    "            value *= 1000000\n",
    "        elif tht == 'billion':\n",
    "            value *= 1000000000\n",
    "        logging.info(f'Value adjusted: {value}')\n",
    "        token = next(token.ancestors)\n",
    "        \n",
    "    # Analyze children and siblings, then ancestors if first was not enough\n",
    "    # TODO: is there a better way?\n",
    "    # TODO: use close nouns as a fallback when it is hard to find a dependency?\n",
    "    # TODO: expand nouns with adjectives or other nouns? (rate -> information transfer rate)\n",
    "    logging.info(f'Token children: {\",\".join(t.text for t in token.children)}')\n",
    "    children_matched = False\n",
    "    for t in token.children:\n",
    "        if process_candidate(metrics, t, value, idx):\n",
    "            logging.info(f'Child term: {t.text}')\n",
    "            children_matched = True\n",
    "        if children_matched:\n",
    "            return\n",
    "    logging.info('Head with children: '\n",
    "                 f'{token.head.text} | {\",\".join(t.text for t in token.head.children)}')  \n",
    "    if process_candidate(metrics, token.head, value, idx):\n",
    "        logging.info(f'Head term: {token.head.text}')\n",
    "        return\n",
    "    \n",
    "    head_children_matched = False\n",
    "    for t in token.head.children:        \n",
    "        if process_candidate(metrics, t, value, idx):\n",
    "            logging.info(f'Child of head term: {t.text}')\n",
    "            head_children_matched = True\n",
    "    if head_children_matched:\n",
    "        return\n",
    "\n",
    "    logging.info(f'Token anscestors: {\",\".join(t.text for t in token.ancestors)}')\n",
    "    for t in token.ancestors:\n",
    "        if process_candidate(metrics, t, value, idx):\n",
    "            logging.info(f'Ancestor: {t.text}')\n",
    "            return\n",
    "\n",
    "def extract_metrics(text, visualize_dependencies=False):\n",
    "    \"\"\"\n",
    "    Parses abstract and returns a dict of numbers with nouns that could be suitable as a metric.\n",
    "    :return list of tuples (sentence, [metrics]), where metrics is a list of tuples (number, [nouns], sentence_number)\n",
    "    \"\"\"   \n",
    "    metrics = {}\n",
    "    sentences = {}\n",
    "    # Convert textual numbers to digits (three -> 3)\n",
    "    text = alpha2digit(text.lower(), 'en', relaxed=True)\n",
    "    # Convect 10th -> 10\n",
    "    text = re.sub(r\"([\\d]+)th\", r\"\\g<1>\", text)\n",
    "    # Split text into sentences and find numbers in sentences\n",
    "    doc = spacy_en(text)\n",
    "    for idx, sent in enumerate(doc.sents):\n",
    "        logging.info('###')\n",
    "        logging.info(sent.text)        \n",
    "        sentences[idx] = sent.text\n",
    "        for token in sent:\n",
    "#             print(token.text, token.pos_, list(token.ancestors))\n",
    "            if NUMBER.fullmatch(token.text):\n",
    "                tt = token.text.replace(',', '')  # TODO: can fail in case of different locale\n",
    "                value = float(tt) if '.' in tt else int(tt)\n",
    "                process_number(token, value, idx, metrics)            \n",
    "        if visualize_dependencies:\n",
    "            displacy.render(sent, style=\"dep\", jupyter=True)\n",
    "    return metrics, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo `extract_metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEXT = \"\"\"\n",
    "No specific antiviral drug has been proven effective for treatment of patients with \n",
    " severe coronavirus disease 2019 (COVID-19).\n",
    "\n",
    "Over brief training periods of 3-24 min, four patients then used these signals \n",
    " to master closed-loop control and to achieve success rates of 74-100% in a \n",
    " one-dimensional binary task.\n",
    "\n",
    "We performed a weighted multivariate analysis of urinary creatinine concentrations in \n",
    " 22,245 participants of the third National Health and Nutrition Examination Survey (1988-1994) \n",
    " and established reference ranges (10th-90th percentiles) for each demographic and age category.\n",
    "\n",
    "Longitudinal descriptive analyses of the 1032 participants in the 1991-2007 \n",
    " National Institute of Child Health and Human Development Study of Early Child Care and \n",
    " Youth Development birth cohort from 10 study sites who had accelerometer-determined minutes of MVPA \n",
    " at ages 9 (year 2000), 11 (2002), 12 (2003), and 15 (2006) years.\n",
    " \n",
    "Hookworm infection occurs in almost half of ssa's poorest people, including 40-50 million school-aged \n",
    "children and 70 million pregnant women in whom it is a leading cause of anemia.\n",
    "\n",
    "For the 2 most mutagenic regimens: 4 x 1 hr in 3 mm enu and 6 x 1', 5: 'hr in 3 mm enu'.\n",
    "\"\"\"\n",
    "\n",
    "metrics, _ = extract_metrics(TEXT, visualize_dependencies=True)\n",
    "for word, occasions in metrics.items():\n",
    "    print(f\"{word}: {occasions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's apply metric extraction to Pubmed papers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude papers with unwanted terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE = ['\\becog', 'electrocorticograph', '\\bhybrid', 'fNIRS', '\\bSSVEP']\n",
    "\n",
    "if len(EXCLUDE) > 0:\n",
    "    EXCLUDE_REGEX = '|'.join(EXCLUDE)\n",
    "    EXCLUDE_MASK = np.logical_not(pub_df.abstract.str.contains(EXCLUDE_REGEX, flags=re.IGNORECASE, regex=True))\n",
    "    processed_pub_df = pub_df[EXCLUDE_MASK]\n",
    "else:\n",
    "    processed_pub_df = pub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ids = set(pub_df['id'])\n",
    "processed_ids = set(processed_pub_df['id'])\n",
    "diff = original_ids - processed_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the list of excluded papers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df[pub_df['id'].isin(diff)][['id', 'abstract']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Metric Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Slow, currently moved out of the class to speed up fixing & rerunning the code of MetricExtractor\n",
    "metrics_data = []\n",
    "for _, data in tqdm(processed_pub_df.iterrows()):\n",
    "    paper_metrics_data = [data['id'], *extract_metrics(data['abstract'])]\n",
    "    metrics_data.append(paper_metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricExtractor:\n",
    "    def __init__(self, metrics_data):\n",
    "        self.metrics_df = pd.DataFrame(metrics_data, columns=['ID', 'Metrics', 'Sentences'])\n",
    "        \n",
    "    def get_top_metrics(self, number=20):\n",
    "        metrics_counter = Counter()\n",
    "        for metric_dict in self.metrics_df['Metrics']:\n",
    "            for metric, occasions in metric_dict.items():\n",
    "                metrics_counter[metric] += len(occasions)\n",
    "        return metrics_counter.most_common(number)\n",
    "    \n",
    "    def get_metric_values(self, *metrics, min_value=None, max_value=None, detailed=False):\n",
    "        values = []\n",
    "        for _, data in self.metrics_df.iterrows():\n",
    "            metric_dict = data['Metrics']\n",
    "            sentences = data['Sentences']\n",
    "        \n",
    "            for metric in metrics:\n",
    "                if metric in metric_dict:\n",
    "                    for value, sentence_number in metric_dict[metric]:\n",
    "                        if min_value and value < min_value or max_value and value > max_value:\n",
    "                            continue\n",
    "                        if detailed:\n",
    "                            sentence = sentences[sentence_number]\n",
    "                            values.append([data['ID'], value, sentence])\n",
    "                        else:\n",
    "                            values.append(value)\n",
    "        if detailed:\n",
    "            return pd.DataFrame(values, columns=['PMID', ', '.join(metrics), 'Sentence'])\n",
    "        return values\n",
    "    \n",
    "    def filter_papers(self, metrics):\n",
    "        \"\"\"\n",
    "        :param metrics - list of tuples ([list of keywords], min_value, max_value)\n",
    "               e.g. (['subjects', 'participants'], 5, None)\n",
    "        :return list of PMIDs\n",
    "        \"\"\"\n",
    "        selection = []\n",
    "        for _, data in self.metrics_df.iterrows():\n",
    "            suitable = True\n",
    "            metric_dict = data['Metrics']\n",
    "            \n",
    "            for metric in metrics:\n",
    "                metric_suitable = False\n",
    "                words, min_value, max_value = metric\n",
    "                \n",
    "                for word in words:\n",
    "                    if word in metric_dict:\n",
    "                        for value, _ in metric_dict[word]:\n",
    "                            if min_value and value < min_value or max_value and value > max_value:\n",
    "                                continue\n",
    "                            metric_suitable = True\n",
    "                    if metric_suitable:\n",
    "                        break\n",
    "                \n",
    "                suitable &= metric_suitable\n",
    "                    \n",
    "            if suitable:\n",
    "                selection.append(data['ID'])\n",
    "        return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = MetricExtractor(metrics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See an example of extraction result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.metrics_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(left=me.metrics_df, left_on='ID', right=pub_df[['id', 'title']], right_on='id')\n",
    "result = result[['ID', 'title', 'Metrics', 'Sentences']]\n",
    "result.to_csv(f'metrics_{SEARCH_QUERY.replace(\" \", \"_\").lower()}.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Frequent Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(me.get_top_metrics(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a metric to show distribution and abstract fragments where it was mentioned.\n",
    "\n",
    "Currently synonyms are not processed, so feel free to use a tuple of words that correspond to the same metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = ('subject', 'patient', 'role', 'participant', 'volunteer', 'people', 'donor', \n",
    "          'man', 'woman', 'male', 'female')\n",
    "METRIC_TEXT = ', '.join(METRIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of selected `METRIC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_subjects = me.get_metric_values(*METRIC)\n",
    "plt.hist(num_subjects)\n",
    "plt.xlabel(METRIC_TEXT)\n",
    "plt.ylabel('Number of papers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.get_metric_values(*METRIC, detailed=True).sort_values(METRIC_TEXT, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter papers based on desired metric values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "METRICS = [\n",
    "    (['subjects', 'patients', 'participants', 'volunteers'], 10, None),\n",
    "    (['accuracy'], 65, None),\n",
    "]\n",
    "\n",
    "selection = me.filter_papers(METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df[pub_df.id.isin(selection)][['id', 'abstract']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with synonims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = wordnet.synsets('patient')\n",
    "set(chain.from_iterable([word.lemma_names() for word in synonyms]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development\n",
    "\n",
    "Other libraries for extraction of metrics/quantities: quantulum, grobid-quantities.\n",
    "\n",
    "Dependencies:\n",
    "  * `pip install quantulum3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantulum3 import parser\n",
    "parser.parse(\"\"\"No specific antiviral drug has been proven effective for treatment of patients with \n",
    " severe coronavirus disease 2019 (COVID-19).\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
