{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataset\n",
    "\n",
    "This notebook contains the code to analyse content of the PubMedCentral Author Manuscript Collection. \\\n",
    "See: https://www.ncbi.nlm.nih.gov/pmc/about/mscollection/\n",
    "\n",
    "Files can be downloaded here: https://ftp.ncbi.nlm.nih.gov/pub/pmc/manuscript/ \\\n",
    "**Please ensure** that files are downloaded into `~/pmc_dataset` folder to proceed.\n",
    "\n",
    "Resulting tables will be created under `~/review/dataset` folder (see `config.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrc.review.config as cfg\n",
    "\n",
    "pmc_dataset_root = os.path.expanduser('~/pmc_dataset')\n",
    "\n",
    "dataset_root = os.path.expanduser(cfg.dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_articles = {}\n",
    "\n",
    "# These files should be downloaded from https://ftp.ncbi.nlm.nih.gov/pub/pmc/manuscript/\n",
    "with open(f\"{pmc_dataset_root}/filelist.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        filename, pmcid, pmid, mid = line.split()\n",
    "        if filename == 'File':\n",
    "            continue\n",
    "        dict_articles[pmid] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(dict_articles.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "tree = etree.parse(pmc_dataset_root + '/' + list(dict_articles.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(tree.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def split_text(text):\n",
    "    sents = nltk.tokenize.sent_tokenize(text)\n",
    "    res_sents = []\n",
    "    i = 0\n",
    "    while i < len(sents):\n",
    "        check = False\n",
    "        if i + 1 < len(sents):\n",
    "            check = sents[i + 1].strip()[0].islower() or sents[i + 1].strip()[0].isdigit()\n",
    "        made = sents[i]\n",
    "        while i + 1 < len(sents) and (made.endswith('Fig.') or check):\n",
    "            made += \" \" + \" \".join(sents[i + 1].strip().split())\n",
    "            i += 1\n",
    "            if i + 1 < len(sents):\n",
    "                check = sents[i + 1].strip()[0].islower() or sents[i + 1].strip()[0].isdigit()\n",
    "        res_sents.append(\" \".join(made.strip().split()))\n",
    "        i += 1\n",
    "    return res_sents\n",
    "\n",
    "def get_sentences(node):\n",
    "    def helper(node, is_disc):\n",
    "        if node.tag == 'xref':\n",
    "            ntail = ''\n",
    "            if node.tail is not None:\n",
    "                ntail = node.tail\n",
    "            res = f' xref_{node.get(\"ref-type\")}_{node.get(\"rid\")} ' + ntail\n",
    "            if res is None:\n",
    "                return '', ''\n",
    "            if is_disc:\n",
    "                return '', res\n",
    "            return res, ''\n",
    "        if node.tag == 'title':\n",
    "            if node.tail is None:\n",
    "                return '', ''\n",
    "            if is_disc:\n",
    "                return '', node.tail\n",
    "            return node.tail, ''\n",
    "        if not is_disc and node.find('title') is not None:\n",
    "            title = \"\".join(node.find('title').itertext()).lower()\n",
    "            if 'discussion' in title:\n",
    "                is_disc = True\n",
    "        st_text = ''\n",
    "        if node.text is not None:\n",
    "            st_text = node.text\n",
    "        if is_disc:\n",
    "            n_disc = st_text\n",
    "            n_gen = \"\"\n",
    "        else:\n",
    "            n_gen = st_text\n",
    "            n_disc = \"\"\n",
    "        for ch in node.getchildren():\n",
    "            gen, disc = helper(ch, is_disc)\n",
    "            n_gen += gen\n",
    "            n_disc += disc\n",
    "        tail = \"\"\n",
    "        if node.tail is not None:\n",
    "            tail = node.tail\n",
    "        if is_disc:\n",
    "            n_disc += tail\n",
    "        else:\n",
    "            n_gen += tail\n",
    "        return n_gen, n_disc\n",
    "    gen_res, disc_res = helper(node.find('body'), False)\n",
    "    gen_res = split_text(gen_res)\n",
    "    disc_res = split_text(disc_res)\n",
    "    \n",
    "    abstract = \"\"\n",
    "    \n",
    "    try:\n",
    "        abstract = \"\".join(node.find('front').find('article-meta').find('abstract').itertext())\n",
    "        abstract = \" \".join(abstract.strip().split())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return gen_res, disc_res, abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse(f\"{pmc_dataset_root}/PMC0020XXXXX/PMC2000292.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = get_sentences(tree.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sents[0]), len(sents[1]), len(sents[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_refs(node):\n",
    "    \n",
    "    def get_cit_id_type(node):\n",
    "        if node.find('element-citation') is None:\n",
    "            return None\n",
    "        if node.find('element-citation').find('pub-id') is None:\n",
    "            return None\n",
    "        return node.find('element-citation').find('pub-id').get('pub-id-type')\n",
    "        \n",
    "    \n",
    "    def get_citation_info(node):\n",
    "        if node is None:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for ch in node.getchildren():\n",
    "            if ch.tag == 'ref':\n",
    "                id_type = get_cit_id_type(ch)\n",
    "                if id_type is not None and id_type == 'pmid':\n",
    "                    res[ch.get('id')] = {\n",
    "                        'publication-type': ch.find('element-citation').get('publication-type'),\n",
    "                        'pmid': ch.find('element-citation').find('pub-id').text\n",
    "                    }\n",
    "        return res\n",
    "    def get_figs_info(node):\n",
    "        if node is None:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for ch in node.getchildren():\n",
    "            if ch.tag == 'fig' and ch.find('caption') is not None:\n",
    "                res[ch.get('id')] = \" \".join(''.join(ch.find('caption').itertext()).strip().split())\n",
    "        return res\n",
    "    def get_tables_info(node):\n",
    "        if node is None:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for ch in node.getchildren():\n",
    "            if ch.tag == 'table-wrap' and ch.find('caption') is not None:\n",
    "                res[ch.get('id')] = \" \".join(''.join(ch.find('caption').itertext()).strip().split())\n",
    "        return res\n",
    "        \n",
    "    citations = get_citation_info(node.find('back').find('ref-list'))\n",
    "    figs = get_figs_info(node.find('floats-group'))\n",
    "    tables = get_tables_info(node.find('floats-group'))\n",
    "    return citations, figs, tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_refs(tree.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(\"(?<=xref_bibr_)[\\d\\w]+\")\n",
    "\n",
    "def count_reverse(sents_gen, sents_disc, pmid):\n",
    "    result = []\n",
    "    for i, sent in enumerate(sents_gen):\n",
    "        results = re.findall(pattern, sent)\n",
    "        result.extend(list(map(lambda x: (pmid, 'general', str(i), x), results)))\n",
    "    for i, sent in enumerate(sents_disc):\n",
    "        results = re.findall(pattern, sent)\n",
    "        result.extend(list(map(lambda x: (pmid, 'discussion', str(i), x), results)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sents, disc_sents, abst = get_sentences(tree.getroot())\n",
    "count_reverse(gen_sents, disc_sents, '2000292')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "num_id = 0\n",
    "\n",
    "for id, filename in list(dict_articles.items()):\n",
    "    print(f'\\r{num_id} {filename}', end='')\n",
    "    num_id += 1\n",
    "    try:\n",
    "        tree = etree.parse(pmc_dataset_root + \"/\" + filename).getroot()\n",
    "        gen_sents, disc_sents, abstract = get_sentences(tree)\n",
    "        cits, figs, tables = get_all_refs(tree)\n",
    "    except Exception as e:\n",
    "        print(\"\\rsomething went wrong\", id, filename, e)\n",
    "        continue\n",
    "    with open(f'{dataset_root}/sentences.csv', 'a') as f:\n",
    "        for i, sent in enumerate(gen_sents):\n",
    "            print('\\t'.join([id, str(i), 'general', sent]), file=f)\n",
    "        for i, sent in enumerate(disc_sents):\n",
    "            print('\\t'.join([id, str(i), 'discussion', sent]), file=f)\n",
    "    if abstract != '':\n",
    "        with open(f'{dataset_root}/abstracts.csv', 'a') as f:\n",
    "            print('\\t'.join([id, abstract]), file=f)\n",
    "    with open(f'{dataset_root}/citations.csv', 'a') as f:\n",
    "        for i, dic in cits.items():\n",
    "            print('\\t'.join([id, str(i), dic['publication-type'], dic['pmid']]), file=f)\n",
    "    with open(f'{dataset_root}/figures.csv', 'a') as f:\n",
    "        for i, text in figs.items():\n",
    "            print('\\t'.join([id, i, text]), file=f)\n",
    "    with open(f'{dataset_root}/tables.csv', 'a') as f:\n",
    "        for i, text in tables.items():\n",
    "            print('\\t'.join([id, i, text]), file=f)\n",
    "    with open(f'{dataset_root}/reverse_ref.csv', 'a') as f:\n",
    "        res = count_reverse(gen_sents, disc_sents, id)\n",
    "        for row in res:\n",
    "            print('\\t'.join(list(row)), file = f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
