{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Semantic search\n",
    "\n",
    "Ready to go models.\n",
    "\n",
    "| Model Name                                                               | Type                | Dim | Quality (Biomedical)                | Speed (CPU)    | Memory Usage            | Sentence-Level Optimized |\n",
    "| ------------------------------------------------------------------------ | ------------------- | --- | ----------------------------------- | -------------- | ----------------------- | ------------------------ |\n",
    "| **BioWordVec (BioSentVec)**<br>`BioWordVec_PubMed_MIMICIII_d200.vec.bin` | Static (word-level) | 200 | ‚ö†Ô∏è Low‚ÄìModerate                     | ‚úÖ‚úÖ‚úÖ Very Fast  | ‚úÖ Very Low (\\~1 GB RAM) | ‚ùå No                     |\n",
    "| **`all-MiniLM-L6-v2`**                                                   | SBERT (MiniLM)      | 384 | ‚úÖ Moderate (general)                | ‚úÖ‚úÖ‚úÖ Very Fast  | ‚úÖ Low (\\~80 MB)         | ‚úÖ Yes                    |\n",
    "| **`pritamdeka/S-PubMedBert-MS-MARCO`**                                   | SBERT (PubMedBERT)  | 768 | ‚úÖ‚úÖ‚úÖ Excellent                       | ‚ö†Ô∏è Medium      | ‚ö†Ô∏è Moderate-High        | ‚úÖ Yes                    |\n",
    "| **`thenlper/gte-base`**                                                  | GTE (BERT)          | 768 | ‚úÖ‚úÖ Good                             | ‚úÖ‚úÖ Fast        | ‚úÖ Moderate (\\~400 MB)   | ‚úÖ Yes                    |\n",
    "| **`nomic-ai/nomic-embed-text-v1.5`**                                     | OpenCLIP-style      | 768 | ‚úÖ‚úÖ Very Good (general + scientific) | ‚ö†Ô∏è Medium-Slow | ‚ùó High (\\~1 GB+)        | ‚ö†Ô∏è Partial (CLS token)   |\n",
    "| **`microsoft/BiomedNLP-PubMedBERT...`**                                  | Raw BERT            | 768 | ‚úÖ‚úÖ‚úÖ Best-in-domain                  | üê¢ Slow        | ‚ùó High (\\~1.2 GB)       | ‚ùå No (needs pooling)     |\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from pysrc.config import PubtrendsConfig\n",
    "\n",
    "config = PubtrendsConfig(test=False)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger('notebook')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chunking"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.papers.analysis.text import get_chunks\n",
    "\n",
    "MAX_TOKENS = 128\n",
    "\n",
    "text = \"Staphylococcus aureus is a rare cause of postinfectious glomerulonephritis, and Staphylococcus-related glo-merulonephritis primarily occurs in middle-aged or elderly patients. Patients with Staphylococcus-related glomerulonephritis also present with hematuria, proteinuria of varying degrees, rising serum creatinine levels, and/or edema. The severity of renal insufficiency is proportional to the degree of proliferation and crescent formation. Here, we present a diabetic patient admitted with a history of 1 week of left elbow pain. Laboratory results revealed that erythrocyte sedimentation rate was 110 mm/hour, serum creatinine level was 1 mg/dL, C-reactive protein level was 150 mg/L, and magnetic resonance imaging showed signal changes in favor of osteomyelitis at the olecranon level, with diffuse edematous appearance in the elbow skin tissue and increased intra-articular effusion. After diagnosis of osteomyelitis, ampicillin/sulbactam and teicoplanin were administered. After day 7 of admission, the patient developed acute kidney injury requiring hemodialysis under antibiotic treatment. Kidney biopsy was performed to determine the underlying cause, which showed Staphylococcus-related glomerulonephritis. Recovery of renal func-tions was observed after antibiotic and supportive treatment.\"\n",
    "\n",
    "chunks = get_chunks(text, MAX_TOKENS)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {i + 1}:\")\n",
    "    print(chunk)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embeddings with Sentence Transformer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.endpoints.embeddings.sentence_transformer.sentence_transformer import SentenceTransformerModel\n",
    "\n",
    "sentence_transformer_model = SentenceTransformerModel()\n",
    "# noinspection PyStatementEffect\n",
    "sentence_transformer_model.download_and_load_model\n",
    "emb = sentence_transformer_model.encode(['This is a test.', 'This is a test2'])\n",
    "print(emb.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embedding_dimension = emb.shape[1]\n",
    "text_embedding = lambda t: sentence_transformer_model.encode(t)\n",
    "batch_texts_embeddings = lambda t: sentence_transformer_model.encode(t)\n",
    "embeddings_model = sentence_transformer_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = sentence_transformer_model.device\n",
    "embeddings_model_name = 'all_MiniLM_L6_v2'\n",
    "embedding_dimension = 384"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embeddings with HugginFace Wrapper model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from more_itertools import sliced\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from transformers import AutoModel, AutoTokenizer\n",
    "#\n",
    "# if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "#     device = 'mps'\n",
    "# elif torch.cuda.is_available():\n",
    "#     device = 'gpu'\n",
    "# else:\n",
    "#     device = 'cpu'\n",
    "#\n",
    "# class SentenceTransformerWrapper:\n",
    "#     def __init__(self, model_name, attention):\n",
    "#         print(f'Loading model into {device}')\n",
    "#         self.device = device\n",
    "#         self.attention = attention\n",
    "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#         self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device)\n",
    "#         self.model.eval()\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def mean_pooling(model_output, attention_mask):\n",
    "#         token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
    "#         input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#         summed = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
    "#         summed_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "#         return summed / summed_mask\n",
    "#\n",
    "#     def encode(self, sentences, batch_size=32):\n",
    "#         all_embeddings = []\n",
    "#\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(list(sliced(sentences, batch_size))):\n",
    "#                 inputs = self.tokenizer(\n",
    "#                     batch,\n",
    "#                     return_tensors=\"pt\",\n",
    "#                     padding=True,\n",
    "#                     truncation=True,\n",
    "#                     max_length=1024,\n",
    "#                 ).to(self.device)\n",
    "#\n",
    "#                 outputs = self.model(**inputs)\n",
    "#                 if self.attention:\n",
    "#                     embeddings = SentenceTransformerWrapper.mean_pooling(outputs, inputs['attention_mask'])\n",
    "#                 else:\n",
    "#                     embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "#\n",
    "#                 all_embeddings.append(embeddings.cpu().numpy())\n",
    "#\n",
    "#         return np.vstack(all_embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Decent model for biomedical embeddings\n",
    "# # wrapped_model = SentenceTransformerWrapper(\"nomic-ai/nomic-embed-text-v1.5\", False)\n",
    "# # Also good, and slightly faster than nomic-embed\n",
    "# wrapped_model = SentenceTransformerWrapper(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", True)\n",
    "# embeddings = wrapped_model.encode('Test sentence')\n",
    "# embeddings.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from more_itertools import sliced\n",
    "# from math import ceil\n",
    "# import concurrent\n",
    "# import multiprocessing\n",
    "# import numpy as np\n",
    "#\n",
    "# def parallel_texts_embeddings_wrapper(texts):\n",
    "#     if device != 'cpu':\n",
    "#         return wrapped_model.encode(texts)\n",
    "#     # Default to number of CPUs for max workers\n",
    "#     max_workers = multiprocessing.cpu_count()\n",
    "#     # Compute parallel on different threads, since we use the same fasttext model\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#         futures = [\n",
    "#             executor.submit(lambda ts: wrapped_model.encode(ts), ts)\n",
    "#                    for ts in sliced(texts, int(ceil(len(texts) / max_workers)))\n",
    "#         ]\n",
    "#         # Important: keep order of results!!!\n",
    "#         return np.vstack([future.result() for future in futures])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# embeddings_model_name = BiomedNLP_PubMedBERT\n",
    "# text_embedding = lambda t: wrapped_model.encode([t])\n",
    "# batch_texts_embeddings = parallel_texts_embeddings_wrapper\n",
    "# embeddings_model = wrapped_model\n",
    "# embedding_dimension = embeddings.shape[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prepare Postgresql + pgvector for embeddings\n",
    "\n",
    "Create DB Postgresql + pgvector\n",
    "```\n",
    "docker run --rm --name pubtrends-postgres -p 5430:5432 \\\n",
    "        -m 32G \\\n",
    "        -e POSTGRES_USER=biolabs -e POSTGRES_PASSWORD=mysecretpassword \\\n",
    "        -e POSTGRES_DB=pubtrends \\\n",
    "        -v ~/pgvector/:/var/lib/postgresql/data \\\n",
    "        -e PGDATA=/var/lib/postgresql/data/pgdata \\\n",
    "        -d pgvector/pgvector:pg17\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Semantic search with Postgresql"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pysrc.preprocess.embeddings.embeddings_model_connector import EmbeddingsModelConnector\n",
    "from pysrc.preprocess.embeddings.embeddings_db_connector import EmbeddingsDBConnector\n",
    "\n",
    "embeddings_model_connector = EmbeddingsModelConnector()\n",
    "\n",
    "embeddings_db_connector = EmbeddingsDBConnector(\n",
    "    host='localhost',\n",
    "    port=5430,\n",
    "    database='pubtrends',\n",
    "    user='biolabs',\n",
    "    password='mysecretpassword',\n",
    "    embeddings_model_name=embeddings_model_connector.embeddings_model_name,\n",
    "    embedding_dimension=embeddings_model_connector.embeddings_dimension\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create an index for fast vector similarity search using cosine distance\n",
    "# Index may slightly change results vs exact match search, but it's much faster!\n",
    "with psycopg2.connect(embeddings_db_connector.connection_string) as connection:\n",
    "    connection.set_session(readonly=False)\n",
    "    query = f'''\n",
    "                CREATE INDEX embedding_idx_{embeddings_model_name}\n",
    "                ON {embeddings_model_name}\n",
    "                USING ivfflat (embedding vector_cosine_ops)\n",
    "                WITH (lists = 100);\n",
    "            '''\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query)\n",
    "    connection.commit()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.endpoints.semantic_search.semantic_search import l2norm\n",
    "\n",
    "\n",
    "def semantic_search_postgresql(query, k):\n",
    "    query_vector = text_embedding(query)\n",
    "    # Normalize embeddings if using cosine similarity\n",
    "    embedding = l2norm(query_vector).tolist()\n",
    "    with psycopg2.connect(embeddings_db_connector.connection_string) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(f\"\"\"\n",
    "                   SELECT pmid, chunk, embedding <=> %s::vector AS distance\n",
    "                   FROM {embeddings_model_name}\n",
    "                   ORDER BY distance\n",
    "                   LIMIT %s\n",
    "                   \"\"\", (embedding, k))\n",
    "\n",
    "            results = cursor.fetchall()\n",
    "            return pd.DataFrame(data=results, columns=['pmid', 'chunk', 'distance'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_pg = semantic_search_postgresql(\"epigenetic human aging\", 1000)\n",
    "search_pg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Semantic search with Faiss"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.preprocess.embeddings.faiss_connector import FaissConnector\n",
    "\n",
    "faiss_connector = FaissConnector(\n",
    "    embeddings_model_name=embeddings_model_connector.embeddings_model_name,\n",
    "    embeddings_dimension=embeddings_model_connector.embeddings_dimension\n",
    ")\n",
    "faiss_connector.create_or_load_faiss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "\n",
    "\n",
    "def semantic_search_faiss(query_text, k):\n",
    "    query_vector = text_embedding(query_text).reshape(1, -1)\n",
    "    # Normalize embeddings if using cosine similarity\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    similarities, indices = faiss_connector.faiss_index.search(query_vector.astype('float32'), k)\n",
    "    t = faiss_connector.pids_idx.iloc[indices[0]].copy().reset_index(drop=True)\n",
    "    t['similarity'] = similarities[0]\n",
    "    return t"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_fs = semantic_search_faiss(\"epigenetic human aging\", 10_000)\n",
    "search_fs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparison Postgresql vs Faiss semantic search"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(f'Postgresql {len(pmids_pg.unique())}')\n",
    "# print(f'Faiss {len(pmids_fs.unique())}')\n",
    "# overlap = set(list(pmids_pg)) & set(list(pmids_fs))\n",
    "# print(f'Overlap {len(overlap)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply additional semantic filtering on search results"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search = semantic_search_faiss(\n",
    "    \"epigenetic changes in stem cell differentiation in human\",\n",
    "    1000\n",
    ")\n",
    "search_ids = search['pmid']\n",
    "print(len(search_ids.unique()))\n",
    "search"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.preprocess.embeddings.publications_db_connector import PublicationsDBConnector\n",
    "\n",
    "publications_db_connector = PublicationsDBConnector()\n",
    "\n",
    "publications = publications_db_connector.load_publications(search_ids)\n",
    "search_ids = publications['id']\n",
    "publications.head(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.papers.analysis.text import parallel_collect_chunks\n",
    "\n",
    "\n",
    "def collect_chunks_embeddings(df):\n",
    "    print('\\rCollecting chunks           ', end='')\n",
    "    pids = list(df['id'])\n",
    "    texts = [f'{title}. {abstract}' for title, abstract in zip(df['title'], df['abstract'])]\n",
    "    chunks, chunk_idx = parallel_collect_chunks(pids, texts, MAX_TOKENS)\n",
    "    print(f'\\rComputing {len(chunks)} embeddings   ', end='')\n",
    "    chunk_embeddings = batch_texts_embeddings(chunks)\n",
    "    return chunk_embeddings, chunk_idx"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Compute documents embeddings')\n",
    "embeddings, chunk_idx = collect_chunks_embeddings(publications)\n",
    "embeddings = [l2norm(e) for e in embeddings]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Compute filters embeddings')\n",
    "\n",
    "positive_filters = ['homo sapience', 'human', 'mammal', 'human cell']\n",
    "negative_filters = ['cancer', 'tumor', 'tumor genesis', 'adenoma', 'carcinoma', 'mouse']\n",
    "\n",
    "print(f'Computing filters embeddings embeddings')\n",
    "negative_filters_embeddings = [l2norm(e) for e in batch_texts_embeddings(positive_filters)]\n",
    "positive_filters_embeddings = [l2norm(e) for e in batch_texts_embeddings(negative_filters)]\n",
    "\n",
    "negative_filters_scores = [(pmid, max([np.dot(e, ne) for ne in negative_filters_embeddings]))\n",
    "                           for (pmid, _), e in zip(chunk_idx, embeddings)]\n",
    "positive_filters_scores = [(pmid, min([np.dot(e, ne) for ne in positive_filters_embeddings]))\n",
    "                           for (pmid, _), e in zip(chunk_idx, embeddings)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "axes = [plt.subplot(1, 3, i + 1) for i in range(3)]\n",
    "ax = axes[0]\n",
    "ns = [s for _, s in negative_filters_scores]\n",
    "sns.histplot(ns, kde=True, ax=ax)\n",
    "ax.set_title('Negative filters')\n",
    "\n",
    "ax = axes[1]\n",
    "ps = [s for _, s in positive_filters_scores]\n",
    "sns.histplot(ps, kde=True, ax=ax)\n",
    "ax.set_title('Positive filters')\n",
    "\n",
    "ax = axes[2]\n",
    "sns.scatterplot(x=ns, y=ps, ax=ax)\n",
    "sns.rugplot(x=ns, y=ps, height=.1, alpha=0.01, ax=ax)\n",
    "ax.set_xlabel('Negative filters')\n",
    "ax.set_ylabel('Positive filters')\n",
    "ax.set_title('Positive filters vs negative filters')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_negative_filter_score = 0.1\n",
    "min_positive_filter_score = 0.05\n",
    "\n",
    "filtered_ids = [\n",
    "    pmid for (pmid, ps), (_, ns) in zip(positive_filters_scores, negative_filters_scores)\n",
    "    if ps > min_positive_filter_score and ns < max_negative_filter_score\n",
    "]\n",
    "\n",
    "filtered_publications = publications_db_connector.load_publications(filtered_ids)\n",
    "filtered_publications['title']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualization of semantic search results\n",
    "\n",
    "Launch fasttext endpoint API so that analyzer can use it\n",
    "  ```\n",
    "  conda activate pubtrends\n",
    "  export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "  python pysrc/fasttext/fasttext_app.py\n",
    "  ```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pysrc.papers.db.pm_postgres_loader import PubmedPostgresLoader\n",
    "from pysrc.papers.analyzer import PapersAnalyzer\n",
    "\n",
    "loader = PubmedPostgresLoader(config)\n",
    "analyzer = PapersAnalyzer(loader, config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    analyzer.analyze_papers(filtered_ids, 5)\n",
    "finally:\n",
    "    loader.close_connection()\n",
    "    analyzer.teardown()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from bokeh.plotting import show\n",
    "from pysrc.papers.plot.plotter import Plotter\n",
    "\n",
    "analyzer.search_ids = filtered_ids\n",
    "plotter = Plotter(config, analyzer)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# show(plotter.plot_top_cited_papers())",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show(plotter.plot_papers_graph())",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show(plotter.topics_hierarchy_with_keywords())",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
